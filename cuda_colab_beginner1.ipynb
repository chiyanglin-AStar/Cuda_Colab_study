{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Er195Vonzia"
      },
      "source": [
        "<a href=\"https://githubtocolab.com/chiyanglin-AStar/Cuda_Colab_study/blob/master/cuda_colab_beginner1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jo3uJgJ2DhB"
      },
      "source": [
        "# Install Nvidia & other dependencies\n",
        "\n",
        "in this version , remove colab have built-in package install steps "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZAHFNCj4St8"
      },
      "source": [
        "# Show our GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvlavcVD4K7W",
        "outputId": "04471b00-d8bd-426c-90f3-a209d66ab5cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 27 04:36:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_cjIVVP4egG"
      },
      "source": [
        "# C Compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv_ejpDm4glG",
        "outputId": "c99972c9-4667-45b3-84f0-55b3621aff36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using built-in specs.\n",
            "COLLECT_GCC=gcc\n",
            "COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/7/lto-wrapper\n",
            "OFFLOAD_TARGET_NAMES=nvptx-none\n",
            "OFFLOAD_TARGET_DEFAULT=1\n",
            "Target: x86_64-linux-gnu\n",
            "Configured with: ../src/configure -v --with-pkgversion='Ubuntu 7.5.0-3ubuntu1~18.04' --with-bugurl=file:///usr/share/doc/gcc-7/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++ --prefix=/usr --with-gcc-major-version-only --program-suffix=-7 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-bootstrap --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\n",
            "Thread model: posix\n",
            "gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04) \n"
          ]
        }
      ],
      "source": [
        "!gcc -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3fQT5o--txn"
      },
      "source": [
        "# Install CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evxzc04GGqH3",
        "outputId": "2488fd20-8745-4707-91a1-8ddee358624c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50rnK3u2DW5I",
        "outputId": "f7ea978c-de14-4e6a-c1f9-5ece9ad0d194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 14.2 kB/88.\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 14.2 kB/88.\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 20.0 kB/88.\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.39\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.39\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connected to developer.download.nvidia.com (152.\r                                                                               \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,990 kB]\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,545 kB]\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:14 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,155 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,322 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,104 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,422 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [20.6 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [64.0 kB]\n",
            "Fetched 13.9 MB in 3s (4,669 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!apt-get update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vCkuZAaqeJA",
        "outputId": "07542811-6b2a-4753-a9e1-94f495c6e319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cmake version 3.22.6\n",
            "\n",
            "CMake suite maintained and supported by Kitware (kitware.com/cmake).\n"
          ]
        }
      ],
      "source": [
        "!cmake --version "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWgJZxS5JMOG"
      },
      "source": [
        "# Colab have install cmake , may not re-install Cmake\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*  CMake is an open-source, cross-platform family of tools \n",
        "*  designed to build, test and package software.\n",
        "*  Used to control the software compilation process.\n",
        "*  by using simple platform and compiler independent configuration files, \n",
        "*  generate native makefiles and workspaces that can be used in the compiler environment of your choice.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "gbrA1dzfKvzg",
        "outputId": "6e4b1b4b-f96e-4dd6-ddc0-76bc120f4d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.9.1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install cmake"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/bin/g* "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auf_gg0z5YOp",
        "outputId": "6a8e70df-449b-42b5-92d4-f05279e1917a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/g++\t\t     /usr/bin/genfio\n",
            "/usr/bin/g++-6\t\t     /usr/bin/genrb\n",
            "/usr/bin/g++-7\t\t     /usr/bin/geos-config\n",
            "/usr/bin/gapplication\t     /usr/bin/geqn\n",
            "/usr/bin/gc\t\t     /usr/bin/getconf\n",
            "/usr/bin/gcc\t\t     /usr/bin/getent\n",
            "/usr/bin/gcc-6\t\t     /usr/bin/getopt\n",
            "/usr/bin/gcc-7\t\t     /usr/bin/gfortran\n",
            "/usr/bin/gcc-ar\t\t     /usr/bin/gfortran-7\n",
            "/usr/bin/gcc-ar-6\t     /usr/bin/gio\n",
            "/usr/bin/gcc-ar-7\t     /usr/bin/gio-querymodules\n",
            "/usr/bin/gcc-nm\t\t     /usr/bin/git\n",
            "/usr/bin/gcc-nm-6\t     /usr/bin/git-lfs\n",
            "/usr/bin/gcc-nm-7\t     /usr/bin/git-receive-pack\n",
            "/usr/bin/gcc-ranlib\t     /usr/bin/git-shell\n",
            "/usr/bin/gcc-ranlib-6\t     /usr/bin/git-upload-archive\n",
            "/usr/bin/gcc-ranlib-7\t     /usr/bin/git-upload-pack\n",
            "/usr/bin/gcov\t\t     /usr/bin/glib-compile-resources\n",
            "/usr/bin/gcov-6\t\t     /usr/bin/glib-compile-schemas\n",
            "/usr/bin/gcov-7\t\t     /usr/bin/glib-genmarshal\n",
            "/usr/bin/gcov-dump\t     /usr/bin/glib-gettextize\n",
            "/usr/bin/gcov-dump-6\t     /usr/bin/glib-mkenums\n",
            "/usr/bin/gcov-dump-7\t     /usr/bin/gml2gv\n",
            "/usr/bin/gcov-tool\t     /usr/bin/gnmanalyse\n",
            "/usr/bin/gcov-tool-6\t     /usr/bin/gnmmanage\n",
            "/usr/bin/gcov-tool-7\t     /usr/bin/gobject-query\n",
            "/usr/bin/gcps2vec.py\t     /usr/bin/gold\n",
            "/usr/bin/gcps2wld.py\t     /usr/bin/google-pprof\n",
            "/usr/bin/gdal2tiles.py\t     /usr/bin/gpasswd\n",
            "/usr/bin/gdal2xyz.py\t     /usr/bin/gpg\n",
            "/usr/bin/gdaladdo\t     /usr/bin/gpg2\n",
            "/usr/bin/gdal_auth.py\t     /usr/bin/gpg-agent\n",
            "/usr/bin/gdalbuildvrt\t     /usr/bin/gpgconf\n",
            "/usr/bin/gdal_calc.py\t     /usr/bin/gpg-connect-agent\n",
            "/usr/bin/gdalchksum.py\t     /usr/bin/gpg-error\n",
            "/usr/bin/gdalcompare.py      /usr/bin/gpg-error-config\n",
            "/usr/bin/gdal-config\t     /usr/bin/gpgparsemail\n",
            "/usr/bin/gdal_contour\t     /usr/bin/gpgsm\n",
            "/usr/bin/gdaldem\t     /usr/bin/gpgsplit\n",
            "/usr/bin/gdal_edit.py\t     /usr/bin/gpgv\n",
            "/usr/bin/gdalenhance\t     /usr/bin/gpg-wks-server\n",
            "/usr/bin/gdal_fillnodata.py  /usr/bin/gpg-zip\n",
            "/usr/bin/gdal_grid\t     /usr/bin/gpic\n",
            "/usr/bin/gdalident.py\t     /usr/bin/gprof\n",
            "/usr/bin/gdalimport.py\t     /usr/bin/gpu-library-advisor\n",
            "/usr/bin/gdalinfo\t     /usr/bin/graphml2gv\n",
            "/usr/bin/gdallocationinfo    /usr/bin/gresource\n",
            "/usr/bin/gdalmanage\t     /usr/bin/groff\n",
            "/usr/bin/gdal_merge.py\t     /usr/bin/grog\n",
            "/usr/bin/gdalmove.py\t     /usr/bin/grops\n",
            "/usr/bin/gdal_pansharpen.py  /usr/bin/grotty\n",
            "/usr/bin/gdal_polygonize.py  /usr/bin/groups\n",
            "/usr/bin/gdal_proximity.py   /usr/bin/gsettings\n",
            "/usr/bin/gdal_rasterize      /usr/bin/gtbl\n",
            "/usr/bin/gdal_retile.py      /usr/bin/gtester\n",
            "/usr/bin/gdalserver\t     /usr/bin/gtester-report\n",
            "/usr/bin/gdal_sieve.py\t     /usr/bin/gtf\n",
            "/usr/bin/gdalsrsinfo\t     /usr/bin/gtk-update-icon-cache\n",
            "/usr/bin/gdaltindex\t     /usr/bin/gv2gml\n",
            "/usr/bin/gdaltransform\t     /usr/bin/gv2gxl\n",
            "/usr/bin/gdal_translate      /usr/bin/gvcolor\n",
            "/usr/bin/gdalwarp\t     /usr/bin/gvgen\n",
            "/usr/bin/gdbus\t\t     /usr/bin/gvmap\n",
            "/usr/bin/gdbus-codegen\t     /usr/bin/gvmap.sh\n",
            "/usr/bin/genbrk\t\t     /usr/bin/gvpack\n",
            "/usr/bin/gencat\t\t     /usr/bin/gvpr\n",
            "/usr/bin/gencfu\t\t     /usr/bin/gxl2dot\n",
            "/usr/bin/gencnval\t     /usr/bin/gxl2gv\n",
            "/usr/bin/gendict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TagN1KWwLPrI"
      },
      "source": [
        "# Upload the Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnLx3pVtLTca",
        "outputId": "93bea512-66a9-4142-87e6-545145771d5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Cuda_Colab_study'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Counting objects: 100% (222/222), done.\u001b[K\n",
            "remote: Compressing objects: 100% (185/185), done.\u001b[K\n",
            "remote: Total 222 (delta 91), reused 124 (delta 34), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (222/222), 2.60 MiB | 17.52 MiB/s, done.\n",
            "Resolving deltas: 100% (91/91), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chiyanglin-AStar/Cuda_Colab_study.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljBaItYiMHaK",
        "outputId": "7717bbd9-5b00-4842-b218-171710576ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/t1/Cuda_Colab_study/nvidia_samples/0_intro/simplePrintf\n"
          ]
        }
      ],
      "source": [
        "%cd ./Cuda_Colab_study/nvidia_samples/0_intro/simplePrintf/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello"
      ],
      "metadata": {
        "id": "Uft8FtA37Otr",
        "outputId": "92b64cb0-20c8-4239-caf4-6d98431be329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printf() is called. Output:\n",
            "\n",
            " hello world \n",
            " "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmmtqCzVMECe",
        "outputId": "6edeec00-115f-45a6-f1e7-3d0f4e09ef92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.out  hello  hello_printf.cu  Makefile  note.md  README.md  simplePrintf.cu\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir t1"
      ],
      "metadata": {
        "id": "kK4ND6sK5yaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd t1"
      ],
      "metadata": {
        "id": "IQhP5Vap5lcU",
        "outputId": "ff399448-7910-49b3-e002-c2164e871182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA tutorial part1\n",
        "ref : https://github.com/CodedK/CUDA-by-Example-source-code-for-the-book-s-examples-\n"
      ],
      "metadata": {
        "id": "7n5fWSM11D2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile book.h\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and\n",
        " * proprietary rights in and to this software and related documentation.\n",
        " * Any use, reproduction, disclosure, or distribution of this software\n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA)\n",
        " * associated with this source code for terms and conditions that govern\n",
        " * your use of this NVIDIA software.\n",
        " *\n",
        " */\n",
        "\n",
        "\n",
        "#ifndef __BOOK_H__\n",
        "#define __BOOK_H__\n",
        "#include <stdio.h>\n",
        "\n",
        "static void HandleError( cudaError_t err,\n",
        "                         const char *file,\n",
        "                         int line ) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ),\n",
        "                file, line );\n",
        "        exit( EXIT_FAILURE );\n",
        "    }\n",
        "}\n",
        "#define HANDLE_ERROR( err ) (HandleError( err, __FILE__, __LINE__ ))\n",
        "\n",
        "\n",
        "#define HANDLE_NULL( a ) {if (a == NULL) { \\\n",
        "                            printf( \"Host memory failed in %s at line %d\\n\", \\\n",
        "                                    __FILE__, __LINE__ ); \\\n",
        "                            exit( EXIT_FAILURE );}}\n",
        "\n",
        "template< typename T >\n",
        "void swap( T& a, T& b ) {\n",
        "    T t = a;\n",
        "    a = b;\n",
        "    b = t;\n",
        "}\n",
        "\n",
        "\n",
        "void* big_random_block( int size ) {\n",
        "    unsigned char *data = (unsigned char*)malloc( size );\n",
        "    HANDLE_NULL( data );\n",
        "    for (int i=0; i<size; i++)\n",
        "        data[i] = rand();\n",
        "\n",
        "    return data;\n",
        "}\n",
        "\n",
        "int* big_random_block_int( int size ) {\n",
        "    int *data = (int*)malloc( size * sizeof(int) );\n",
        "    HANDLE_NULL( data );\n",
        "    for (int i=0; i<size; i++)\n",
        "        data[i] = rand();\n",
        "\n",
        "    return data;\n",
        "}\n",
        "\n",
        "\n",
        "// a place for common kernels - starts here\n",
        "\n",
        "__device__ unsigned char value( float n1, float n2, int hue ) {\n",
        "    if (hue > 360)      hue -= 360;\n",
        "    else if (hue < 0)   hue += 360;\n",
        "\n",
        "    if (hue < 60)\n",
        "        return (unsigned char)(255 * (n1 + (n2-n1)*hue/60));\n",
        "    if (hue < 180)\n",
        "        return (unsigned char)(255 * n2);\n",
        "    if (hue < 240)\n",
        "        return (unsigned char)(255 * (n1 + (n2-n1)*(240-hue)/60));\n",
        "    return (unsigned char)(255 * n1);\n",
        "}\n",
        "\n",
        "__global__ void float_to_color( unsigned char *optr,\n",
        "                              const float *outSrc ) {\n",
        "    // map from threadIdx/BlockIdx to pixel position\n",
        "    int x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int offset = x + y * blockDim.x * gridDim.x;\n",
        "\n",
        "    float l = outSrc[offset];\n",
        "    float s = 1;\n",
        "    int h = (180 + (int)(360.0f * outSrc[offset])) % 360;\n",
        "    float m1, m2;\n",
        "\n",
        "    if (l <= 0.5f)\n",
        "        m2 = l * (1 + s);\n",
        "    else\n",
        "        m2 = l + s - l * s;\n",
        "    m1 = 2 * l - m2;\n",
        "\n",
        "    optr[offset*4 + 0] = value( m1, m2, h+120 );\n",
        "    optr[offset*4 + 1] = value( m1, m2, h );\n",
        "    optr[offset*4 + 2] = value( m1, m2, h -120 );\n",
        "    optr[offset*4 + 3] = 255;\n",
        "}\n",
        "\n",
        "__global__ void float_to_color( uchar4 *optr,\n",
        "                              const float *outSrc ) {\n",
        "    // map from threadIdx/BlockIdx to pixel position\n",
        "    int x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int offset = x + y * blockDim.x * gridDim.x;\n",
        "\n",
        "    float l = outSrc[offset];\n",
        "    float s = 1;\n",
        "    int h = (180 + (int)(360.0f * outSrc[offset])) % 360;\n",
        "    float m1, m2;\n",
        "\n",
        "    if (l <= 0.5f)\n",
        "        m2 = l * (1 + s);\n",
        "    else\n",
        "        m2 = l + s - l * s;\n",
        "    m1 = 2 * l - m2;\n",
        "\n",
        "    optr[offset].x = value( m1, m2, h+120 );\n",
        "    optr[offset].y = value( m1, m2, h );\n",
        "    optr[offset].z = value( m1, m2, h -120 );\n",
        "    optr[offset].w = 255;\n",
        "}\n",
        "\n",
        "\n",
        "#if _WIN32\n",
        "    //Windows threads.\n",
        "    #include <windows.h>\n",
        "\n",
        "    typedef HANDLE CUTThread;\n",
        "    typedef unsigned (WINAPI *CUT_THREADROUTINE)(void *);\n",
        "\n",
        "    #define CUT_THREADPROC unsigned WINAPI\n",
        "    #define  CUT_THREADEND return 0\n",
        "\n",
        "#else\n",
        "    //POSIX threads.\n",
        "    #include <pthread.h>\n",
        "\n",
        "    typedef pthread_t CUTThread;\n",
        "    typedef void *(*CUT_THREADROUTINE)(void *);\n",
        "\n",
        "    #define CUT_THREADPROC void\n",
        "    #define  CUT_THREADEND\n",
        "#endif\n",
        "\n",
        "//Create thread.\n",
        "CUTThread start_thread( CUT_THREADROUTINE, void *data );\n",
        "\n",
        "//Wait for thread to finish.\n",
        "void end_thread( CUTThread thread );\n",
        "\n",
        "//Destroy thread.\n",
        "void destroy_thread( CUTThread thread );\n",
        "\n",
        "//Wait for multiple threads.\n",
        "void wait_for_threads( const CUTThread *threads, int num );\n",
        "\n",
        "#if _WIN32\n",
        "    //Create thread\n",
        "    CUTThread start_thread(CUT_THREADROUTINE func, void *data){\n",
        "        return CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)func, data, 0, NULL);\n",
        "    }\n",
        "\n",
        "    //Wait for thread to finish\n",
        "    void end_thread(CUTThread thread){\n",
        "        WaitForSingleObject(thread, INFINITE);\n",
        "        CloseHandle(thread);\n",
        "    }\n",
        "\n",
        "    //Destroy thread\n",
        "    void destroy_thread( CUTThread thread ){\n",
        "        TerminateThread(thread, 0);\n",
        "        CloseHandle(thread);\n",
        "    }\n",
        "\n",
        "    //Wait for multiple threads\n",
        "    void wait_for_threads(const CUTThread * threads, int num){\n",
        "        WaitForMultipleObjects(num, threads, true, INFINITE);\n",
        "\n",
        "        for(int i = 0; i < num; i++)\n",
        "            CloseHandle(threads[i]);\n",
        "    }\n",
        "\n",
        "#else\n",
        "    //Create thread\n",
        "    CUTThread start_thread(CUT_THREADROUTINE func, void * data){\n",
        "        pthread_t thread;\n",
        "        pthread_create(&thread, NULL, func, data);\n",
        "        return thread;\n",
        "    }\n",
        "\n",
        "    //Wait for thread to finish\n",
        "    void end_thread(CUTThread thread){\n",
        "        pthread_join(thread, NULL);\n",
        "    }\n",
        "\n",
        "    //Destroy thread\n",
        "    void destroy_thread( CUTThread thread ){\n",
        "        pthread_cancel(thread);\n",
        "    }\n",
        "\n",
        "    //Wait for multiple threads\n",
        "    void wait_for_threads(const CUTThread * threads, int num){\n",
        "        for(int i = 0; i < num; i++)\n",
        "            end_thread( threads[i] );\n",
        "    }\n",
        "\n",
        "#endif\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#endif  // __BOOK_H__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7_EZLQi0XA-",
        "outputId": "77aaa73e-9dd9-4b44-9413-ed3559c4afe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting book.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "int main( void ) {\n",
        "    printf( \"Hello, World!\\n\" );\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOMudY4ROfjN",
        "outputId": "7f491c47-554f-4a88-c482-1ca466a3d4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc hello.cu -o hello"
      ],
      "metadata": {
        "id": "YNKhm2LVOuKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm hello"
      ],
      "metadata": {
        "id": "EgBaaNMi4F9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -o hello hello.cu"
      ],
      "metadata": {
        "id": "T_fKdM-R376z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4DiI7n7O-CY",
        "outputId": "6b77131f-0fa2-4206-ed1f-c3005a248ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "book.h\tcuda_basic_tutorial.ipynb  hello  hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guOFlMWLPlFd",
        "outputId": "53221483-b087-4c72-a329-1f388bfd861d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile simple_kernel.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "__global__ void kernel( void ) {\n",
        "}\n",
        "\n",
        "int main( void ) {\n",
        "    kernel<<<1,1>>>();\n",
        "    printf( \"Hello, World!\\n\" );\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJNK13QC1ldM",
        "outputId": "852ca8e2-93bd-4523-ca73-214525a26c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing simple_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc simple_kernel.cu"
      ],
      "metadata": {
        "id": "i3vPlOm11zFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF17cG5114w8",
        "outputId": "bb660067-c4ab-4941-a72a-ccaf055b98ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile simple_kernel_para.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "__global__ void add( int a, int b, int *c ) {\n",
        "    *c = a + b;\n",
        "}\n",
        "\n",
        "int main( void ) {\n",
        "    int c;\n",
        "    int *dev_c;\n",
        "    HANDLE_ERROR( cudaMalloc( (void**)&dev_c, sizeof(int) ) );\n",
        "\n",
        "    add<<<1,1>>>( 2, 7, dev_c );\n",
        "\n",
        "    HANDLE_ERROR( cudaMemcpy( &c, dev_c, sizeof(int),\n",
        "                              cudaMemcpyDeviceToHost ) );\n",
        "    printf( \"2 + 7 = %d\\n\", c );\n",
        "    HANDLE_ERROR( cudaFree( dev_c ) );\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqKOu33I2k4k",
        "outputId": "999935ac-397c-4146-8cd9-4ba6647f17d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing simple_kernel_para.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc simple_kernel_para.cu"
      ],
      "metadata": {
        "id": "wwfT8Xnn2aQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJDSO2Y124B7",
        "outputId": "9c511e7d-ff55-4ed8-9bdd-52a759a621a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 + 7 = 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile simple_device_call.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "__device__ int addem( int a, int b ) {\n",
        "    return a + b;\n",
        "}\n",
        "\n",
        "__global__ void add( int a, int b, int *c ) {\n",
        "    *c = addem( a, b );\n",
        "}\n",
        "\n",
        "int main( void ) {\n",
        "    int c;\n",
        "    int *dev_c;\n",
        "    HANDLE_ERROR( cudaMalloc( (void**)&dev_c, sizeof(int) ) );\n",
        "\n",
        "    add<<<1,1>>>( 2, 7, dev_c );\n",
        "\n",
        "    HANDLE_ERROR( cudaMemcpy( &c, dev_c, sizeof(int),\n",
        "                              cudaMemcpyDeviceToHost ) );\n",
        "    printf( \"2 + 7 = %d\\n\", c );\n",
        "    HANDLE_ERROR( cudaFree( dev_c ) );\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwPaaswo27Ij",
        "outputId": "a07171ec-a634-486f-bbf2-f47a5294a86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing simple_device_call.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc simple_device_call.cu"
      ],
      "metadata": {
        "id": "qG-zoJuP3QRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lvRCUbp3UPr",
        "outputId": "6626ebdf-18bb-4444-ee1c-f6e0dba4ecff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 + 7 = 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile enum_gpu.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "int main( void ) {\n",
        "    cudaDeviceProp  prop;\n",
        "\n",
        "    int count;\n",
        "    HANDLE_ERROR( cudaGetDeviceCount( &count ) );\n",
        "    for (int i=0; i< count; i++) {\n",
        "        HANDLE_ERROR( cudaGetDeviceProperties( &prop, i ) );\n",
        "        printf( \"   --- General Information for device %d ---\\n\", i );\n",
        "        printf( \"Name:  %s\\n\", prop.name );\n",
        "        printf( \"Compute capability:  %d.%d\\n\", prop.major, prop.minor );\n",
        "        printf( \"Clock rate:  %d\\n\", prop.clockRate );\n",
        "        printf( \"Device copy overlap:  \" );\n",
        "        if (prop.deviceOverlap)\n",
        "            printf( \"Enabled\\n\" );\n",
        "        else\n",
        "            printf( \"Disabled\\n\");\n",
        "        printf( \"Kernel execution timeout :  \" );\n",
        "        if (prop.kernelExecTimeoutEnabled)\n",
        "            printf( \"Enabled\\n\" );\n",
        "        else\n",
        "            printf( \"Disabled\\n\" );\n",
        "\n",
        "        printf( \"   --- Memory Information for device %d ---\\n\", i );\n",
        "        printf( \"Total global mem:  %ld\\n\", prop.totalGlobalMem );\n",
        "        printf( \"Total constant Mem:  %ld\\n\", prop.totalConstMem );\n",
        "        printf( \"Max mem pitch:  %ld\\n\", prop.memPitch );\n",
        "        printf( \"Texture Alignment:  %ld\\n\", prop.textureAlignment );\n",
        "\n",
        "        printf( \"   --- MP Information for device %d ---\\n\", i );\n",
        "        printf( \"Multiprocessor count:  %d\\n\",\n",
        "                    prop.multiProcessorCount );\n",
        "        printf( \"Shared mem per mp:  %ld\\n\", prop.sharedMemPerBlock );\n",
        "        printf( \"Registers per mp:  %d\\n\", prop.regsPerBlock );\n",
        "        printf( \"Threads in warp:  %d\\n\", prop.warpSize );\n",
        "        printf( \"Max threads per block:  %d\\n\",\n",
        "                    prop.maxThreadsPerBlock );\n",
        "        printf( \"Max thread dimensions:  (%d, %d, %d)\\n\",\n",
        "                    prop.maxThreadsDim[0], prop.maxThreadsDim[1],\n",
        "                    prop.maxThreadsDim[2] );\n",
        "        printf( \"Max grid dimensions:  (%d, %d, %d)\\n\",\n",
        "                    prop.maxGridSize[0], prop.maxGridSize[1],\n",
        "                    prop.maxGridSize[2] );\n",
        "        printf( \"\\n\" );\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNLWMAcb3bL9",
        "outputId": "07aaca14-7ab6-4231-8698-33cbc7cd9a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing enum_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc enum_gpu.cu"
      ],
      "metadata": {
        "id": "jYYo3F0c3tf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dbEu4cB3xP2",
        "outputId": "a6834331-fe88-467e-baed-8f09d3d7941a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   --- General Information for device 0 ---\n",
            "Name:  Tesla T4\n",
            "Compute capability:  7.5\n",
            "Clock rate:  1590000\n",
            "Device copy overlap:  Enabled\n",
            "Kernel execution timeout :  Disabled\n",
            "   --- Memory Information for device 0 ---\n",
            "Total global mem:  15843721216\n",
            "Total constant Mem:  65536\n",
            "Max mem pitch:  2147483647\n",
            "Texture Alignment:  512\n",
            "   --- MP Information for device 0 ---\n",
            "Multiprocessor count:  40\n",
            "Shared mem per mp:  49152\n",
            "Registers per mp:  65536\n",
            "Threads in warp:  32\n",
            "Max threads per block:  1024\n",
            "Max thread dimensions:  (1024, 1024, 64)\n",
            "Max grid dimensions:  (2147483647, 65535, 65535)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile set_gpu.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "int main( void ) {\n",
        "    cudaDeviceProp  prop;\n",
        "    int dev;\n",
        "\n",
        "    HANDLE_ERROR( cudaGetDevice( &dev ) );\n",
        "    printf( \"ID of current CUDA device:  %d\\n\", dev );\n",
        "\n",
        "    memset( &prop, 0, sizeof( cudaDeviceProp ) );\n",
        "    prop.major = 1;\n",
        "    prop.minor = 3;\n",
        "    HANDLE_ERROR( cudaChooseDevice( &dev, &prop ) );\n",
        "    printf( \"ID of CUDA device closest to revision 1.3:  %d\\n\", dev );\n",
        "\n",
        "    HANDLE_ERROR( cudaSetDevice( dev ) );\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzUdFjIT37gL",
        "outputId": "24d84f7c-576f-4a72-c9ba-e18726c8fc05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing set_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc set_gpu.cu"
      ],
      "metadata": {
        "id": "9UDti8Qr4MCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7_Frn-s4T8z",
        "outputId": "238f3362-ad87-40cd-e42b-dd0e737484ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID of current CUDA device:  0\n",
            "ID of CUDA device closest to revision 1.3:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aJrNyoNJt4v",
        "outputId": "254bd897-98e3-43b6-9e94-dfe0c60d8ccc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-ap1m0dk4\n",
            "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-ap1m0dk4\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4306 sha256=ad3b1a1720741ccb31abe6213d5492003668eb0569bb035b19b8e4529fae99d1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e3q2968d/wheels/ca/33/8d/3c86eb85e97d2b6169d95c6e8f2c297fdec60db6e84cb56f5e\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPCLbxXtGbXt",
        "outputId": "1c334d4e-2205-4c98-fdd4-3b2d8761e7ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<iostream>\n",
        "void c_hello(){\n",
        "    printf(\"Hello World!\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    c_hello();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25289631-291a-478c-ac0e-db0896b70b47",
        "id": "bX2TiALNRYyf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<iostream>\n",
        "#include<stdio.h>\n",
        "using namespace std;\n",
        "__global__ void cuda_hello(){\n",
        "    \n",
        "    printf(\" hello world from GPU! \\n\");\n",
        "    //cout << \"Hello World from GPU!\\n\";\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    cuda_hello<<<1,1>>>(); \n",
        "    printf(\" hello world from main! \\n\");\n",
        "    cudaDeviceSynchronize();\n",
        "    //cout << \"hello world from main!\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwvnqvY25Ion",
        "outputId": "0c7dfe3a-01dd-41ed-d5d5-f27a06715078"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " hello world from main! \n",
            " hello world from GPU! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CPU Version -- Vector add\n",
        "ref : https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/"
      ],
      "metadata": {
        "id": "W3VvjHN179xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu \n",
        "#include<stdio.h>\n",
        "#define N 10000000\n",
        "\n",
        "void vector_add(float *out, float *a, float *b, int n) {\n",
        "    for(int i = 0; i < n; i++){\n",
        "        out[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float *a, *b, *out; \n",
        "    int  i;\n",
        "\n",
        "    // Allocate memory\n",
        "    a   = (float*)malloc(sizeof(float) * N);\n",
        "    b   = (float*)malloc(sizeof(float) * N);\n",
        "    out = (float*)malloc(sizeof(float) * N);\n",
        "\n",
        "    // Initialize array\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f; b[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    // Main function\n",
        "    vector_add(out, a, b, N);\n",
        "    for(i=0;i<5;i++){\n",
        "        printf(\"%f + %f = %f\\n\",a[i],b[i],out[i]);\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4r2bLNH78-b",
        "outputId": "acfe6319-2a12-4be1-dcf3-c3dd9a8a2251"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_div_cpu.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#define N 10000000\n",
        "\n",
        "void vector_add(float *out, float *a, float *b, int n) {\n",
        "    for(int i = 0; i < n; i++){\n",
        "        out[i] = a[i] / b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float *a, *b, *out; \n",
        "    int  i;\n",
        "\n",
        "    // Allocate memory\n",
        "    a   = (float*)malloc(sizeof(float) * N);\n",
        "    b   = (float*)malloc(sizeof(float) * N);\n",
        "    out = (float*)malloc(sizeof(float) * N);\n",
        "\n",
        "    // Initialize array\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f; b[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    // Main function\n",
        "    vector_add(out, a, b, N);\n",
        "    for(i=0;i<5;i++){\n",
        "        printf(\"%f + %f = %f\\n\",a[i],b[i],out[i]);\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjzPQ0MMORyY",
        "outputId": "9608ce8f-3112-4d87-a8c9-6fab40aadef6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_div_cpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPGPU version --  Vector add\n",
        "ref : https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/ "
      ],
      "metadata": {
        "id": "GwteycTl8z5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<stdio.h> \n",
        "static void HandleError( cudaError_t err,const char *file,int line ) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ),\n",
        "                file, line );\n",
        "        exit( EXIT_FAILURE );\n",
        "    }\n",
        "}\n",
        "#define HANDLE_ERROR( err ) (HandleError( err, __FILE__, __LINE__ )) \n",
        "#define N 10000000\n",
        "__global__ void vector_add(float *out, float *a, float *b, int n) {\n",
        "    for(int i = 0; i < n; i++){\n",
        "        out[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float *a, *b, *out; \n",
        "    float *d_a,*d_b,*d_out;\n",
        "    int   i;\n",
        "    // Allocate memory\n",
        "    #if 1\n",
        "    a   = (float*)malloc(sizeof(float) * N);\n",
        "    b   = (float*)malloc(sizeof(float) * N);\n",
        "    out  = (float*)malloc(sizeof(float) * N);\n",
        "    #else \n",
        "    HANDLE_ERROR(cudaMalloc(a,sizeof(float) * N));\n",
        "    HANDLE_ERROR(cudaMalloc(b,sizeof(float) * N));\n",
        "    HANDLE_ERROR(cudaMalloc(c,sizeof(float) * N));\n",
        "    #endif \n",
        "\n",
        "    // Initialize array\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f; b[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    // Main function\n",
        "    #if 0 \n",
        "    vector_add(out, a, b, N);\n",
        "    #else\n",
        "\n",
        "    // Allocate device memory for a\n",
        "    HANDLE_ERROR(cudaMalloc((void**)&d_a, sizeof(float) * N));\n",
        "    HANDLE_ERROR(cudaMalloc((void**)&d_b, sizeof(float) * N));\n",
        "    HANDLE_ERROR(cudaMalloc((void**)&d_out, sizeof(float) * N));\n",
        "\n",
        "    // Transfer data from host to device memory\n",
        "    HANDLE_ERROR(cudaMemcpy(d_a, a, sizeof(float) * N, cudaMemcpyHostToDevice));\n",
        "    HANDLE_ERROR(cudaMemcpy(d_b, b, sizeof(float) * N, cudaMemcpyHostToDevice));\n",
        "    HANDLE_ERROR(cudaMemcpy(d_out, out, sizeof(float) * N, cudaMemcpyHostToDevice));\n",
        "\n",
        "    vector_add<<<1,1>>>(d_out, d_a, d_b, N);\n",
        "    HANDLE_ERROR(cudaMemcpy(out, d_out, sizeof(float) * N, cudaMemcpyDeviceToHost));\n",
        "    for(i=0;i<5;i++){\n",
        "        printf(\"%f + %f = %f\\n\",a[i],b[i],out[i]);\n",
        "    }\n",
        "    // Cleanup after kernel execution\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_out);\n",
        "    #endif\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(out);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2ZpGvn27FyW",
        "outputId": "18191def-114c-4434-f52a-92eef0f0fdba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_div_gpu.cu\n",
        "#include<stdio.h> \n",
        "static void HandleError( cudaError_t err,const char *file,int line ) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ),\n",
        "                file, line );\n",
        "        exit( EXIT_FAILURE );\n",
        "    }\n",
        "}\n",
        "#define HANDLE_ERROR( err ) (HandleError( err, __FILE__, __LINE__ )) \n",
        "#define N 10000000\n",
        "__global__ void vector_add(float *out, float *a, float *b, int n) {\n",
        "    for(int i = 0; i < n; i++){\n",
        "        out[i] = a[i] / b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float *a, *b, *out; \n",
        "    float *d_a,*d_b,*d_out;\n",
        "    int   i;\n",
        "    // Allocate memory\n",
        "    #if 1\n",
        "    a   = (float*)malloc(sizeof(float) * N);\n",
        "    b   = (float*)malloc(sizeof(float) * N);\n",
        "    out  = (float*)malloc(sizeof(float) * N);\n",
        "    #else \n",
        "    HANDLE_ERROR(cudaMalloc(a,sizeof(float) * N));\n",
        "    HANDLE_ERROR(cudaMalloc(b,sizeof(float) * N));\n",
        "    HANDLE_ERROR(cudaMalloc(c,sizeof(float) * N));\n",
        "    #endif \n",
        "\n",
        "    // Initialize array\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f; b[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    // Main function\n",
        "    #if 0 \n",
        "    vector_add(out, a, b, N);\n",
        "    #else\n",
        "\n",
        "    // Allocate device memory for a\n",
        "    HANDLE_ERROR(cudaMalloc((void**)&d_a, sizeof(float) * N));\n",
        "    HANDLE_ERROR(cudaMalloc((void**)&d_b, sizeof(float) * N));\n",
        "    HANDLE_ERROR(cudaMalloc((void**)&d_out, sizeof(float) * N));\n",
        "\n",
        "    // Transfer data from host to device memory\n",
        "    HANDLE_ERROR(cudaMemcpy(d_a, a, sizeof(float) * N, cudaMemcpyHostToDevice));\n",
        "    HANDLE_ERROR(cudaMemcpy(d_b, b, sizeof(float) * N, cudaMemcpyHostToDevice));\n",
        "    HANDLE_ERROR(cudaMemcpy(d_out, out, sizeof(float) * N, cudaMemcpyHostToDevice));\n",
        "\n",
        "    vector_add<<<16,16>>>(d_out, d_a, d_b, N);\n",
        "    HANDLE_ERROR(cudaMemcpy(out, d_out, sizeof(float) * N, cudaMemcpyDeviceToHost));\n",
        "    for(i=0;i<5;i++){\n",
        "        printf(\"%f + %f = %f\\n\",a[i],b[i],out[i]);\n",
        "    }\n",
        "    // Cleanup after kernel execution\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_out);\n",
        "    #endif\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(out);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecMH2A6pOizA",
        "outputId": "6f809ced-f84a-4491-dbdf-4b31bba5b35f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_div_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs6EjFzqPRkX",
        "outputId": "fac72943-418d-42b2-cf98-aa0429bf4bbe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda_Colab_study  src\t vector_add_cpu.cu  vector_div_cpu.cu  v_gpu\n",
            "sample_data\t  v_cpu  vector_add_gpu.cu  vector_div_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vector_div_cpu.cu -o v_cpu"
      ],
      "metadata": {
        "id": "1pvgwAfFPUhf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vector_div_gpu.cu -o v_gpu"
      ],
      "metadata": {
        "id": "5xZH_3MCPc3m"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!time ./v_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdnc5CVePjt6",
        "outputId": "caf3f1be-b4e2-46b1-dd3d-4f7617a625f4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.000000 + 2.000000 = 0.500000\n",
            "1.000000 + 2.000000 = 0.500000\n",
            "1.000000 + 2.000000 = 0.500000\n",
            "1.000000 + 2.000000 = 0.500000\n",
            "1.000000 + 2.000000 = 0.500000\n",
            "\n",
            "real\t0m0.114s\n",
            "user\t0m0.062s\n",
            "sys\t0m0.049s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB_JFFpvPQz8",
        "outputId": "08161756-3388-41e7-dc20-b66aea83019c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvprof: NVIDIA (R) Cuda command line profiler\n",
            "Copyright (c) 2012 - 2020 NVIDIA Corporation\n",
            "Release version 11.1.105 (21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./v_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ooYaLRdPqGS",
        "outputId": "82091ced-fa03-443c-a52f-b1e3138338db"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==671== NVPROF is profiling process 671, command: ./v_gpu\n",
            "1.000000 + 2.000000 = 0.500000\n",
            "1.000000 + 2.000000 = 0.500000\n",
            "1.000000 + 2.000000 = 0.500000\n",
            "1.000000 + 2.000000 = 0.500000\n",
            "1.000000 + 2.000000 = 0.500000\n",
            "==671== Profiling application: ./v_gpu\n",
            "==671== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   95.62%  1.40452s         1  1.40452s  1.40452s  1.40452s  vector_add(float*, float*, float*, int)\n",
            "                    2.44%  35.835ms         1  35.835ms  35.835ms  35.835ms  [CUDA memcpy DtoH]\n",
            "                    1.94%  28.564ms         3  9.5212ms  8.1690ms  12.035ms  [CUDA memcpy HtoD]\n",
            "      API calls:   82.97%  1.47078s         4  367.70ms  8.3824ms  1.44146s  cudaMemcpy\n",
            "                   16.87%  298.97ms         3  99.657ms  177.84us  298.59ms  cudaMalloc\n",
            "                    0.13%  2.2556ms         3  751.88us  227.60us  1.0171ms  cudaFree\n",
            "                    0.02%  347.01us         1  347.01us  347.01us  347.01us  cuDeviceTotalMem\n",
            "                    0.01%  172.22us       101  1.7050us     136ns  76.647us  cuDeviceGetAttribute\n",
            "                    0.00%  30.072us         1  30.072us  30.072us  30.072us  cuDeviceGetName\n",
            "                    0.00%  28.132us         1  28.132us  28.132us  28.132us  cudaLaunchKernel\n",
            "                    0.00%  6.8770us         1  6.8770us  6.8770us  6.8770us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.5880us         3     529ns     185ns  1.0430us  cuDeviceGetCount\n",
            "                    0.00%  1.2350us         2     617ns     314ns     921ns  cuDeviceGet\n",
            "                    0.00%     252ns         1     252ns     252ns     252ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "// System includes\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "\n",
        "// CUDA runtime\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// helper functions and utilities to work with CUDA\n",
        "//#include <helper_functions.h>\n",
        "//#include <helper_cuda.h>\n",
        "\n",
        "\n",
        "__global__ void testKernel(void) {\n",
        "  printf(\" hello world \\n \");\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "  \n",
        "  printf(\"printf() is called. Output:\\n\\n\");\n",
        "\n",
        "  // Kernel configuration, where a two-dimensional grid and\n",
        "  // three-dimensional blocks are configured.\n",
        "  \n",
        "  testKernel<<<1,1>>>();\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  return EXIT_SUCCESS;\n",
        "}"
      ],
      "metadata": {
        "id": "OUW1B-as73L3",
        "outputId": "91a886b4-f8bb-490e-9b8a-dc8702670dd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printf() is called. Output:\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CUDA-GPU-simple.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('shims')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
