{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Er195Vonzia"
      },
      "source": [
        "<a href=\"https://githubtocolab.com/chiyanglin-AStar/Cuda_Colab_study/blob/master/nvidia_samples/nvidia_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jo3uJgJ2DhB"
      },
      "source": [
        "# Install Nvidia & other dependencies\n",
        "\n",
        "in this version , remove colab have built-in package install steps "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZAHFNCj4St8"
      },
      "source": [
        "# Show our GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvlavcVD4K7W",
        "outputId": "0c0ee820-f622-4fac-d76e-7cb7317ef6d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 27 03:31:41 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_cjIVVP4egG"
      },
      "source": [
        "# C Compiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3fQT5o--txn"
      },
      "source": [
        "# Check CUDA Compiler "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evxzc04GGqH3",
        "outputId": "0584b8a6-a025-420c-c354-e36d9213bdc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TagN1KWwLPrI"
      },
      "source": [
        "# Upload your Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnLx3pVtLTca",
        "outputId": "58140f35-56fd-48c3-cee4-81a769139357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Cuda_Colab_study'...\n",
            "remote: Enumerating objects: 218, done.\u001b[K\n",
            "remote: Counting objects: 100% (218/218), done.\u001b[K\n",
            "remote: Compressing objects: 100% (181/181), done.\u001b[K\n",
            "remote: Total 218 (delta 88), reused 124 (delta 34), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (218/218), 2.60 MiB | 5.64 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chiyanglin-AStar/Cuda_Colab_study.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljBaItYiMHaK",
        "outputId": "7717bbd9-5b00-4842-b218-171710576ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/t1/Cuda_Colab_study/nvidia_samples/0_intro/simplePrintf\n"
          ]
        }
      ],
      "source": [
        "%cd ./Cuda_Colab_study/nvidia_samples/0_intro/simplePrintf/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello"
      ],
      "metadata": {
        "id": "Uft8FtA37Otr",
        "outputId": "92b64cb0-20c8-4239-caf4-6d98431be329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printf() is called. Output:\n",
            "\n",
            " hello world \n",
            " "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmmtqCzVMECe",
        "outputId": "6edeec00-115f-45a6-f1e7-3d0f4e09ef92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.out  hello  hello_printf.cu  Makefile  note.md  README.md  simplePrintf.cu\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA tutorial part1\n",
        "ref : https://github.com/CodedK/CUDA-by-Example-source-code-for-the-book-s-examples-\n"
      ],
      "metadata": {
        "id": "7n5fWSM11D2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile book.h\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and\n",
        " * proprietary rights in and to this software and related documentation.\n",
        " * Any use, reproduction, disclosure, or distribution of this software\n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA)\n",
        " * associated with this source code for terms and conditions that govern\n",
        " * your use of this NVIDIA software.\n",
        " *\n",
        " */\n",
        "\n",
        "\n",
        "#ifndef __BOOK_H__\n",
        "#define __BOOK_H__\n",
        "#include <stdio.h>\n",
        "\n",
        "static void HandleError( cudaError_t err,\n",
        "                         const char *file,\n",
        "                         int line ) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ),\n",
        "                file, line );\n",
        "        exit( EXIT_FAILURE );\n",
        "    }\n",
        "}\n",
        "#define HANDLE_ERROR( err ) (HandleError( err, __FILE__, __LINE__ ))\n",
        "\n",
        "\n",
        "#define HANDLE_NULL( a ) {if (a == NULL) { \\\n",
        "                            printf( \"Host memory failed in %s at line %d\\n\", \\\n",
        "                                    __FILE__, __LINE__ ); \\\n",
        "                            exit( EXIT_FAILURE );}}\n",
        "\n",
        "template< typename T >\n",
        "void swap( T& a, T& b ) {\n",
        "    T t = a;\n",
        "    a = b;\n",
        "    b = t;\n",
        "}\n",
        "\n",
        "\n",
        "void* big_random_block( int size ) {\n",
        "    unsigned char *data = (unsigned char*)malloc( size );\n",
        "    HANDLE_NULL( data );\n",
        "    for (int i=0; i<size; i++)\n",
        "        data[i] = rand();\n",
        "\n",
        "    return data;\n",
        "}\n",
        "\n",
        "int* big_random_block_int( int size ) {\n",
        "    int *data = (int*)malloc( size * sizeof(int) );\n",
        "    HANDLE_NULL( data );\n",
        "    for (int i=0; i<size; i++)\n",
        "        data[i] = rand();\n",
        "\n",
        "    return data;\n",
        "}\n",
        "\n",
        "\n",
        "// a place for common kernels - starts here\n",
        "\n",
        "__device__ unsigned char value( float n1, float n2, int hue ) {\n",
        "    if (hue > 360)      hue -= 360;\n",
        "    else if (hue < 0)   hue += 360;\n",
        "\n",
        "    if (hue < 60)\n",
        "        return (unsigned char)(255 * (n1 + (n2-n1)*hue/60));\n",
        "    if (hue < 180)\n",
        "        return (unsigned char)(255 * n2);\n",
        "    if (hue < 240)\n",
        "        return (unsigned char)(255 * (n1 + (n2-n1)*(240-hue)/60));\n",
        "    return (unsigned char)(255 * n1);\n",
        "}\n",
        "\n",
        "__global__ void float_to_color( unsigned char *optr,\n",
        "                              const float *outSrc ) {\n",
        "    // map from threadIdx/BlockIdx to pixel position\n",
        "    int x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int offset = x + y * blockDim.x * gridDim.x;\n",
        "\n",
        "    float l = outSrc[offset];\n",
        "    float s = 1;\n",
        "    int h = (180 + (int)(360.0f * outSrc[offset])) % 360;\n",
        "    float m1, m2;\n",
        "\n",
        "    if (l <= 0.5f)\n",
        "        m2 = l * (1 + s);\n",
        "    else\n",
        "        m2 = l + s - l * s;\n",
        "    m1 = 2 * l - m2;\n",
        "\n",
        "    optr[offset*4 + 0] = value( m1, m2, h+120 );\n",
        "    optr[offset*4 + 1] = value( m1, m2, h );\n",
        "    optr[offset*4 + 2] = value( m1, m2, h -120 );\n",
        "    optr[offset*4 + 3] = 255;\n",
        "}\n",
        "\n",
        "__global__ void float_to_color( uchar4 *optr,\n",
        "                              const float *outSrc ) {\n",
        "    // map from threadIdx/BlockIdx to pixel position\n",
        "    int x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int offset = x + y * blockDim.x * gridDim.x;\n",
        "\n",
        "    float l = outSrc[offset];\n",
        "    float s = 1;\n",
        "    int h = (180 + (int)(360.0f * outSrc[offset])) % 360;\n",
        "    float m1, m2;\n",
        "\n",
        "    if (l <= 0.5f)\n",
        "        m2 = l * (1 + s);\n",
        "    else\n",
        "        m2 = l + s - l * s;\n",
        "    m1 = 2 * l - m2;\n",
        "\n",
        "    optr[offset].x = value( m1, m2, h+120 );\n",
        "    optr[offset].y = value( m1, m2, h );\n",
        "    optr[offset].z = value( m1, m2, h -120 );\n",
        "    optr[offset].w = 255;\n",
        "}\n",
        "\n",
        "\n",
        "#if _WIN32\n",
        "    //Windows threads.\n",
        "    #include <windows.h>\n",
        "\n",
        "    typedef HANDLE CUTThread;\n",
        "    typedef unsigned (WINAPI *CUT_THREADROUTINE)(void *);\n",
        "\n",
        "    #define CUT_THREADPROC unsigned WINAPI\n",
        "    #define  CUT_THREADEND return 0\n",
        "\n",
        "#else\n",
        "    //POSIX threads.\n",
        "    #include <pthread.h>\n",
        "\n",
        "    typedef pthread_t CUTThread;\n",
        "    typedef void *(*CUT_THREADROUTINE)(void *);\n",
        "\n",
        "    #define CUT_THREADPROC void\n",
        "    #define  CUT_THREADEND\n",
        "#endif\n",
        "\n",
        "//Create thread.\n",
        "CUTThread start_thread( CUT_THREADROUTINE, void *data );\n",
        "\n",
        "//Wait for thread to finish.\n",
        "void end_thread( CUTThread thread );\n",
        "\n",
        "//Destroy thread.\n",
        "void destroy_thread( CUTThread thread );\n",
        "\n",
        "//Wait for multiple threads.\n",
        "void wait_for_threads( const CUTThread *threads, int num );\n",
        "\n",
        "#if _WIN32\n",
        "    //Create thread\n",
        "    CUTThread start_thread(CUT_THREADROUTINE func, void *data){\n",
        "        return CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)func, data, 0, NULL);\n",
        "    }\n",
        "\n",
        "    //Wait for thread to finish\n",
        "    void end_thread(CUTThread thread){\n",
        "        WaitForSingleObject(thread, INFINITE);\n",
        "        CloseHandle(thread);\n",
        "    }\n",
        "\n",
        "    //Destroy thread\n",
        "    void destroy_thread( CUTThread thread ){\n",
        "        TerminateThread(thread, 0);\n",
        "        CloseHandle(thread);\n",
        "    }\n",
        "\n",
        "    //Wait for multiple threads\n",
        "    void wait_for_threads(const CUTThread * threads, int num){\n",
        "        WaitForMultipleObjects(num, threads, true, INFINITE);\n",
        "\n",
        "        for(int i = 0; i < num; i++)\n",
        "            CloseHandle(threads[i]);\n",
        "    }\n",
        "\n",
        "#else\n",
        "    //Create thread\n",
        "    CUTThread start_thread(CUT_THREADROUTINE func, void * data){\n",
        "        pthread_t thread;\n",
        "        pthread_create(&thread, NULL, func, data);\n",
        "        return thread;\n",
        "    }\n",
        "\n",
        "    //Wait for thread to finish\n",
        "    void end_thread(CUTThread thread){\n",
        "        pthread_join(thread, NULL);\n",
        "    }\n",
        "\n",
        "    //Destroy thread\n",
        "    void destroy_thread( CUTThread thread ){\n",
        "        pthread_cancel(thread);\n",
        "    }\n",
        "\n",
        "    //Wait for multiple threads\n",
        "    void wait_for_threads(const CUTThread * threads, int num){\n",
        "        for(int i = 0; i < num; i++)\n",
        "            end_thread( threads[i] );\n",
        "    }\n",
        "\n",
        "#endif\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#endif  // __BOOK_H__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7_EZLQi0XA-",
        "outputId": "77aaa73e-9dd9-4b44-9413-ed3559c4afe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting book.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "int main( void ) {\n",
        "    printf( \"Hello, World!\\n\" );\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOMudY4ROfjN",
        "outputId": "7f491c47-554f-4a88-c482-1ca466a3d4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc hello.cu -o hello"
      ],
      "metadata": {
        "id": "YNKhm2LVOuKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm hello"
      ],
      "metadata": {
        "id": "EgBaaNMi4F9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4DiI7n7O-CY",
        "outputId": "6b77131f-0fa2-4206-ed1f-c3005a248ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "book.h\tcuda_basic_tutorial.ipynb  hello  hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guOFlMWLPlFd",
        "outputId": "53221483-b087-4c72-a329-1f388bfd861d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile simple_kernel.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "__global__ void kernel( void ) {\n",
        "}\n",
        "\n",
        "int main( void ) {\n",
        "    kernel<<<1,1>>>();\n",
        "    printf( \"Hello, World!\\n\" );\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJNK13QC1ldM",
        "outputId": "852ca8e2-93bd-4523-ca73-214525a26c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing simple_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc simple_kernel.cu"
      ],
      "metadata": {
        "id": "i3vPlOm11zFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF17cG5114w8",
        "outputId": "bb660067-c4ab-4941-a72a-ccaf055b98ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile simple_kernel_para.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "__global__ void add( int a, int b, int *c ) {\n",
        "    *c = a + b;\n",
        "}\n",
        "\n",
        "int main( void ) {\n",
        "    int c;\n",
        "    int *dev_c;\n",
        "    HANDLE_ERROR( cudaMalloc((void**)&dev_c,sizeof(int)));\n",
        "\n",
        "    add<<<1,1>>>(2,7,dev_c);\n",
        "\n",
        "    HANDLE_ERROR(cudaMemcpy(&c,dev_c,sizeof(int),cudaMemcpyDeviceToHost));\n",
        "    printf(\"2 + 7 = %d\\n\", c);\n",
        "    HANDLE_ERROR(cudaFree(dev_c));\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqKOu33I2k4k",
        "outputId": "999935ac-397c-4146-8cd9-4ba6647f17d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing simple_kernel_para.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc simple_kernel_para.cu"
      ],
      "metadata": {
        "id": "wwfT8Xnn2aQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJDSO2Y124B7",
        "outputId": "9c511e7d-ff55-4ed8-9bdd-52a759a621a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 + 7 = 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile simple_device_call.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "__device__ int addem( int a, int b ) {\n",
        "    return a + b;\n",
        "}\n",
        "\n",
        "__global__ void add(inta,int b,int *c) {\n",
        "    *c = addem( a, b );\n",
        "}\n",
        "\n",
        "int main( void ) {\n",
        "    int c;\n",
        "    int *dev_c;\n",
        "    HANDLE_ERROR(cudaMalloc((void**)&dev_c,sizeof(int)));\n",
        "\n",
        "    add<<<1,1>>>(2,7,dev_c);\n",
        "\n",
        "    HANDLE_ERROR(cudaMemcpy(&c,dev_c,sizeof(int),cudaMemcpyDeviceToHost));\n",
        "    printf(\"2 + 7 = %d\\n\",c);\n",
        "    HANDLE_ERROR(cudaFree(dev_c));\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwPaaswo27Ij",
        "outputId": "a07171ec-a634-486f-bbf2-f47a5294a86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing simple_device_call.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc simple_device_call.cu"
      ],
      "metadata": {
        "id": "qG-zoJuP3QRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lvRCUbp3UPr",
        "outputId": "6626ebdf-18bb-4444-ee1c-f6e0dba4ecff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 + 7 = 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile enum_gpu.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "#include \"book.h\"\n",
        "int main(void) {\n",
        "    cudaDeviceProp  prop;\n",
        "\n",
        "    int count;\n",
        "    HANDLE_ERROR(cudaGetDeviceCount(&count));\n",
        "    for (int i=0; i< count; i++) {\n",
        "        HANDLE_ERROR( cudaGetDeviceProperties( &prop, i ) );\n",
        "        printf( \"   --- General Information for device %d ---\\n\", i );\n",
        "        printf( \"Name:  %s\\n\", prop.name );\n",
        "        printf( \"Compute capability:  %d.%d\\n\", prop.major, prop.minor );\n",
        "        printf( \"Clock rate:  %d\\n\", prop.clockRate );\n",
        "        printf( \"Device copy overlap:  \" );\n",
        "        if (prop.deviceOverlap)\n",
        "            printf( \"Enabled\\n\" );\n",
        "        else\n",
        "            printf( \"Disabled\\n\");\n",
        "        printf( \"Kernel execution timeout :  \" );\n",
        "        if (prop.kernelExecTimeoutEnabled)\n",
        "            printf( \"Enabled\\n\" );\n",
        "        else\n",
        "            printf( \"Disabled\\n\" );\n",
        "\n",
        "        printf( \"   --- Memory Information for device %d ---\\n\", i );\n",
        "        printf( \"Total global mem:  %ld\\n\", prop.totalGlobalMem );\n",
        "        printf( \"Total constant Mem:  %ld\\n\", prop.totalConstMem );\n",
        "        printf( \"Max mem pitch:  %ld\\n\", prop.memPitch );\n",
        "        printf( \"Texture Alignment:  %ld\\n\", prop.textureAlignment );\n",
        "\n",
        "        printf( \"   --- MP Information for device %d ---\\n\", i );\n",
        "        printf( \"Multiprocessor count:  %d\\n\",\n",
        "                    prop.multiProcessorCount );\n",
        "        printf( \"Shared mem per mp:  %ld\\n\", prop.sharedMemPerBlock );\n",
        "        printf( \"Registers per mp:  %d\\n\", prop.regsPerBlock );\n",
        "        printf( \"Threads in warp:  %d\\n\", prop.warpSize );\n",
        "        printf( \"Max threads per block:  %d\\n\",\n",
        "                    prop.maxThreadsPerBlock );\n",
        "        printf( \"Max thread dimensions:  (%d, %d, %d)\\n\",\n",
        "                    prop.maxThreadsDim[0], prop.maxThreadsDim[1],\n",
        "                    prop.maxThreadsDim[2] );\n",
        "        printf( \"Max grid dimensions:  (%d, %d, %d)\\n\",\n",
        "                    prop.maxGridSize[0], prop.maxGridSize[1],\n",
        "                    prop.maxGridSize[2] );\n",
        "        printf( \"\\n\" );\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNLWMAcb3bL9",
        "outputId": "07aaca14-7ab6-4231-8698-33cbc7cd9a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing enum_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc enum_gpu.cu"
      ],
      "metadata": {
        "id": "jYYo3F0c3tf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dbEu4cB3xP2",
        "outputId": "a6834331-fe88-467e-baed-8f09d3d7941a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   --- General Information for device 0 ---\n",
            "Name:  Tesla T4\n",
            "Compute capability:  7.5\n",
            "Clock rate:  1590000\n",
            "Device copy overlap:  Enabled\n",
            "Kernel execution timeout :  Disabled\n",
            "   --- Memory Information for device 0 ---\n",
            "Total global mem:  15843721216\n",
            "Total constant Mem:  65536\n",
            "Max mem pitch:  2147483647\n",
            "Texture Alignment:  512\n",
            "   --- MP Information for device 0 ---\n",
            "Multiprocessor count:  40\n",
            "Shared mem per mp:  49152\n",
            "Registers per mp:  65536\n",
            "Threads in warp:  32\n",
            "Max threads per block:  1024\n",
            "Max thread dimensions:  (1024, 1024, 64)\n",
            "Max grid dimensions:  (2147483647, 65535, 65535)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile set_gpu.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "#include \"book.h\"\n",
        "int main(void) {\n",
        "    cudaDeviceProp  prop;\n",
        "    int dev;\n",
        "\n",
        "    HANDLE_ERROR(cudaGetDevice(&dev));\n",
        "    printf(\"ID of current CUDA device:  %d\\n\",dev);\n",
        "\n",
        "    memset(&prop,0,sizeof(cudaDeviceProp));\n",
        "    prop.major = 1;\n",
        "    prop.minor = 3;\n",
        "    HANDLE_ERROR( cudaChooseDevice(&dev,&prop));\n",
        "    printf(\"ID of CUDA device closest to revision 1.3:  %d\\n\",dev);\n",
        "\n",
        "    HANDLE_ERROR(cudaSetDevice(dev));\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzUdFjIT37gL",
        "outputId": "24d84f7c-576f-4a72-c9ba-e18726c8fc05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing set_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc set_gpu.cu"
      ],
      "metadata": {
        "id": "9UDti8Qr4MCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7_Frn-s4T8z",
        "outputId": "238f3362-ad87-40cd-e42b-dd0e737484ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID of current CUDA device:  0\n",
            "ID of CUDA device closest to revision 1.3:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aJrNyoNJt4v",
        "outputId": "c0b528a8-e32c-4249-8cfb-46a898ce36e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-9y5ep3v5\n",
            "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-9y5ep3v5\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4306 sha256=dfc622b3d78aadada290d0f0029ea7cb143864b535e5ef589f00cc3d9b1aee3c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hj4nnext/wheels/ca/33/8d/3c86eb85e97d2b6169d95c6e8f2c297fdec60db6e84cb56f5e\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPCLbxXtGbXt",
        "outputId": "3327ac31-bc32-4bed-8b9f-57bb92ba4dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<iostream>\n",
        "void c_hello(){\n",
        "    printf(\"Hello World!\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    c_hello();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b76498e-d359-4efa-aa4a-256e97cea44d",
        "id": "bX2TiALNRYyf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<iostream>\n",
        "#include<stdio.h>\n",
        "using namespace std;\n",
        "__global__ void cuda_hello(){    \n",
        "    printf(\" hello world from GPU! \\n\");\n",
        "    //cout << \"Hello World from GPU!\\n\";\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    cuda_hello<<<1,1>>>(); \n",
        "    printf(\" hello world from main! \\n\");\n",
        "    cudaDeviceSynchronize();\n",
        "    //cout << \"hello world from main!\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwvnqvY25Ion",
        "outputId": "2076da9b-873a-4b12-e405-debf584fc727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " hello world from main! \n",
            " hello world from GPU! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CPU Version -- Vector add\n",
        "ref : https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/"
      ],
      "metadata": {
        "id": "W3VvjHN179xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu \n",
        "#include<stdio.h>\n",
        "#define N 10000000\n",
        "\n",
        "void vector_add(float *out, float *a, float *b, int n) {\n",
        "    for(int i = 0; i < n; i++){\n",
        "        out[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float *a, *b, *out; \n",
        "    int  i;\n",
        "\n",
        "    // Allocate memory\n",
        "    a   = (float*)malloc(sizeof(float) * N);\n",
        "    b   = (float*)malloc(sizeof(float) * N);\n",
        "    out = (float*)malloc(sizeof(float) * N);\n",
        "\n",
        "    // Initialize array\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f; b[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    // Main function\n",
        "    vector_add(out, a, b, N);\n",
        "    for(i=0;i<5;i++){\n",
        "        printf(\"%f + %f = %f\\n\",a[i],b[i],out[i]);\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "H4r2bLNH78-b",
        "outputId": "acfe6319-2a12-4be1-dcf3-c3dd9a8a2251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPGPU version --  Vector add\n",
        "ref : https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/ "
      ],
      "metadata": {
        "id": "GwteycTl8z5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<stdio.h> \n",
        "static void HandleError( cudaError_t err,const char *file,int line ) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ),\n",
        "                file, line );\n",
        "        exit( EXIT_FAILURE );\n",
        "    }\n",
        "}\n",
        "#define HANDLE_ERROR( err ) (HandleError( err, __FILE__, __LINE__ )) \n",
        "#define N 10000000\n",
        "__global__ void vector_add(float *out, float *a, float *b, int n) {\n",
        "    for(int i = 0; i < n; i++){\n",
        "        out[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float *a, *b, *out; \n",
        "    float *d_a,*d_b,*d_out;\n",
        "    int   i;\n",
        "    // Allocate memory\n",
        "    #if 1\n",
        "    a   = (float*)malloc(sizeof(float) * N);\n",
        "    b   = (float*)malloc(sizeof(float) * N);\n",
        "    out  = (float*)malloc(sizeof(float) * N);\n",
        "    #else \n",
        "    HANDLE_ERROR(cudaMalloc(a,sizeof(float) * N));\n",
        "    HANDLE_ERROR(cudaMalloc(b,sizeof(float) * N));\n",
        "    HANDLE_ERROR(cudaMalloc(c,sizeof(float) * N));\n",
        "    #endif \n",
        "\n",
        "    // Initialize array\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f; b[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    // Main function\n",
        "    #if 0 \n",
        "    vector_add(out, a, b, N);\n",
        "    #else\n",
        "\n",
        "    // Allocate device memory for a\n",
        "    HANDLE_ERROR(cudaMalloc((void**)&d_a, sizeof(float) * N));\n",
        "    HANDLE_ERROR(cudaMalloc((void**)&d_b, sizeof(float) * N));\n",
        "    HANDLE_ERROR(cudaMalloc((void**)&d_out, sizeof(float) * N));\n",
        "\n",
        "    // Transfer data from host to device memory\n",
        "    HANDLE_ERROR(cudaMemcpy(d_a, a, sizeof(float) * N, cudaMemcpyHostToDevice));\n",
        "    HANDLE_ERROR(cudaMemcpy(d_b, b, sizeof(float) * N, cudaMemcpyHostToDevice));\n",
        "    HANDLE_ERROR(cudaMemcpy(d_out, out, sizeof(float) * N, cudaMemcpyHostToDevice));\n",
        "\n",
        "    vector_add<<<1,1>>>(d_out, d_a, d_b, N);\n",
        "    HANDLE_ERROR(cudaMemcpy(out, d_out, sizeof(float) * N, cudaMemcpyDeviceToHost));\n",
        "    for(i=0;i<5;i++){\n",
        "        printf(\"%f + %f = %f\\n\",a[i],b[i],out[i]);\n",
        "    }\n",
        "    // Cleanup after kernel execution\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_out);\n",
        "    #endif\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(out);\n",
        "}\n"
      ],
      "metadata": {
        "id": "b2ZpGvn27FyW",
        "outputId": "18191def-114c-4434-f52a-92eef0f0fdba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "1.000000 + 2.000000 = 3.000000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB_JFFpvPQz8",
        "outputId": "08161756-3388-41e7-dc20-b66aea83019c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvprof: NVIDIA (R) Cuda command line profiler\n",
            "Copyright (c) 2012 - 2020 NVIDIA Corporation\n",
            "Release version 11.1.105 (21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "// System includes\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "\n",
        "// CUDA runtime\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// helper functions and utilities to work with CUDA\n",
        "//#include <helper_functions.h>\n",
        "//#include <helper_cuda.h>\n",
        "\n",
        "\n",
        "__global__ void testKernel(void) {\n",
        "  printf(\" hello world \\n \");\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "  \n",
        "  printf(\"printf() is called. Output:\\n\\n\");\n",
        "\n",
        "  // Kernel configuration, where a two-dimensional grid and\n",
        "  // three-dimensional blocks are configured.\n",
        "  \n",
        "  testKernel<<<1,1>>>();\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  return EXIT_SUCCESS;\n",
        "}"
      ],
      "metadata": {
        "id": "OUW1B-as73L3",
        "outputId": "91a886b4-f8bb-490e-9b8a-dc8702670dd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printf() is called. Output:\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CUDA-GPU-simple.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('shims')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}