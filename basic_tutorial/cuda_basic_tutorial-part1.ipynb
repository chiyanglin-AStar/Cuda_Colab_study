{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Er195Vonzia"
      },
      "source": [
        "<a href=\"https://githubtocolab.com/chiyanglin-AStar/Cuda_Colab_study/blob/master/basic_tutorial/cuda_basic_tutorial-simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jo3uJgJ2DhB"
      },
      "source": [
        "# Install Nvidia & other dependencies\n",
        "\n",
        "in this version , remove colab have built-in package install steps "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZAHFNCj4St8"
      },
      "source": [
        "# Show our GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvlavcVD4K7W",
        "outputId": "70b23c21-e63d-4968-b379-2eab7898c588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 26 03:19:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_cjIVVP4egG"
      },
      "source": [
        "# C Compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv_ejpDm4glG",
        "outputId": "c99972c9-4667-45b3-84f0-55b3621aff36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using built-in specs.\n",
            "COLLECT_GCC=gcc\n",
            "COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/7/lto-wrapper\n",
            "OFFLOAD_TARGET_NAMES=nvptx-none\n",
            "OFFLOAD_TARGET_DEFAULT=1\n",
            "Target: x86_64-linux-gnu\n",
            "Configured with: ../src/configure -v --with-pkgversion='Ubuntu 7.5.0-3ubuntu1~18.04' --with-bugurl=file:///usr/share/doc/gcc-7/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++ --prefix=/usr --with-gcc-major-version-only --program-suffix=-7 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-bootstrap --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\n",
            "Thread model: posix\n",
            "gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04) \n"
          ]
        }
      ],
      "source": [
        "!gcc -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3fQT5o--txn"
      },
      "source": [
        "# Install CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evxzc04GGqH3",
        "outputId": "b384adb3-c122-4633-f5e6-8d16160eb93d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50rnK3u2DW5I",
        "outputId": "f7ea978c-de14-4e6a-c1f9-5ece9ad0d194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 14.2 kB/88.\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 14.2 kB/88.\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 20.0 kB/88.\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.39\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.39\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connected to developer.download.nvidia.com (152.\r                                                                               \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,990 kB]\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,545 kB]\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:14 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,155 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,322 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,104 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,422 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [20.6 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [64.0 kB]\n",
            "Fetched 13.9 MB in 3s (4,669 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!apt-get update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vCkuZAaqeJA",
        "outputId": "07542811-6b2a-4753-a9e1-94f495c6e319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cmake version 3.22.6\n",
            "\n",
            "CMake suite maintained and supported by Kitware (kitware.com/cmake).\n"
          ]
        }
      ],
      "source": [
        "!cmake --version "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWgJZxS5JMOG"
      },
      "source": [
        "# Colab have install cmake , may not re-install Cmake\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*  CMake is an open-source, cross-platform family of tools \n",
        "*  designed to build, test and package software.\n",
        "*  Used to control the software compilation process.\n",
        "*  by using simple platform and compiler independent configuration files, \n",
        "*  generate native makefiles and workspaces that can be used in the compiler environment of your choice.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "gbrA1dzfKvzg",
        "outputId": "6e4b1b4b-f96e-4dd6-ddc0-76bc120f4d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.9.1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install cmake"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/bin/g* "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auf_gg0z5YOp",
        "outputId": "6a8e70df-449b-42b5-92d4-f05279e1917a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/g++\t\t     /usr/bin/genfio\n",
            "/usr/bin/g++-6\t\t     /usr/bin/genrb\n",
            "/usr/bin/g++-7\t\t     /usr/bin/geos-config\n",
            "/usr/bin/gapplication\t     /usr/bin/geqn\n",
            "/usr/bin/gc\t\t     /usr/bin/getconf\n",
            "/usr/bin/gcc\t\t     /usr/bin/getent\n",
            "/usr/bin/gcc-6\t\t     /usr/bin/getopt\n",
            "/usr/bin/gcc-7\t\t     /usr/bin/gfortran\n",
            "/usr/bin/gcc-ar\t\t     /usr/bin/gfortran-7\n",
            "/usr/bin/gcc-ar-6\t     /usr/bin/gio\n",
            "/usr/bin/gcc-ar-7\t     /usr/bin/gio-querymodules\n",
            "/usr/bin/gcc-nm\t\t     /usr/bin/git\n",
            "/usr/bin/gcc-nm-6\t     /usr/bin/git-lfs\n",
            "/usr/bin/gcc-nm-7\t     /usr/bin/git-receive-pack\n",
            "/usr/bin/gcc-ranlib\t     /usr/bin/git-shell\n",
            "/usr/bin/gcc-ranlib-6\t     /usr/bin/git-upload-archive\n",
            "/usr/bin/gcc-ranlib-7\t     /usr/bin/git-upload-pack\n",
            "/usr/bin/gcov\t\t     /usr/bin/glib-compile-resources\n",
            "/usr/bin/gcov-6\t\t     /usr/bin/glib-compile-schemas\n",
            "/usr/bin/gcov-7\t\t     /usr/bin/glib-genmarshal\n",
            "/usr/bin/gcov-dump\t     /usr/bin/glib-gettextize\n",
            "/usr/bin/gcov-dump-6\t     /usr/bin/glib-mkenums\n",
            "/usr/bin/gcov-dump-7\t     /usr/bin/gml2gv\n",
            "/usr/bin/gcov-tool\t     /usr/bin/gnmanalyse\n",
            "/usr/bin/gcov-tool-6\t     /usr/bin/gnmmanage\n",
            "/usr/bin/gcov-tool-7\t     /usr/bin/gobject-query\n",
            "/usr/bin/gcps2vec.py\t     /usr/bin/gold\n",
            "/usr/bin/gcps2wld.py\t     /usr/bin/google-pprof\n",
            "/usr/bin/gdal2tiles.py\t     /usr/bin/gpasswd\n",
            "/usr/bin/gdal2xyz.py\t     /usr/bin/gpg\n",
            "/usr/bin/gdaladdo\t     /usr/bin/gpg2\n",
            "/usr/bin/gdal_auth.py\t     /usr/bin/gpg-agent\n",
            "/usr/bin/gdalbuildvrt\t     /usr/bin/gpgconf\n",
            "/usr/bin/gdal_calc.py\t     /usr/bin/gpg-connect-agent\n",
            "/usr/bin/gdalchksum.py\t     /usr/bin/gpg-error\n",
            "/usr/bin/gdalcompare.py      /usr/bin/gpg-error-config\n",
            "/usr/bin/gdal-config\t     /usr/bin/gpgparsemail\n",
            "/usr/bin/gdal_contour\t     /usr/bin/gpgsm\n",
            "/usr/bin/gdaldem\t     /usr/bin/gpgsplit\n",
            "/usr/bin/gdal_edit.py\t     /usr/bin/gpgv\n",
            "/usr/bin/gdalenhance\t     /usr/bin/gpg-wks-server\n",
            "/usr/bin/gdal_fillnodata.py  /usr/bin/gpg-zip\n",
            "/usr/bin/gdal_grid\t     /usr/bin/gpic\n",
            "/usr/bin/gdalident.py\t     /usr/bin/gprof\n",
            "/usr/bin/gdalimport.py\t     /usr/bin/gpu-library-advisor\n",
            "/usr/bin/gdalinfo\t     /usr/bin/graphml2gv\n",
            "/usr/bin/gdallocationinfo    /usr/bin/gresource\n",
            "/usr/bin/gdalmanage\t     /usr/bin/groff\n",
            "/usr/bin/gdal_merge.py\t     /usr/bin/grog\n",
            "/usr/bin/gdalmove.py\t     /usr/bin/grops\n",
            "/usr/bin/gdal_pansharpen.py  /usr/bin/grotty\n",
            "/usr/bin/gdal_polygonize.py  /usr/bin/groups\n",
            "/usr/bin/gdal_proximity.py   /usr/bin/gsettings\n",
            "/usr/bin/gdal_rasterize      /usr/bin/gtbl\n",
            "/usr/bin/gdal_retile.py      /usr/bin/gtester\n",
            "/usr/bin/gdalserver\t     /usr/bin/gtester-report\n",
            "/usr/bin/gdal_sieve.py\t     /usr/bin/gtf\n",
            "/usr/bin/gdalsrsinfo\t     /usr/bin/gtk-update-icon-cache\n",
            "/usr/bin/gdaltindex\t     /usr/bin/gv2gml\n",
            "/usr/bin/gdaltransform\t     /usr/bin/gv2gxl\n",
            "/usr/bin/gdal_translate      /usr/bin/gvcolor\n",
            "/usr/bin/gdalwarp\t     /usr/bin/gvgen\n",
            "/usr/bin/gdbus\t\t     /usr/bin/gvmap\n",
            "/usr/bin/gdbus-codegen\t     /usr/bin/gvmap.sh\n",
            "/usr/bin/genbrk\t\t     /usr/bin/gvpack\n",
            "/usr/bin/gencat\t\t     /usr/bin/gvpr\n",
            "/usr/bin/gencfu\t\t     /usr/bin/gxl2dot\n",
            "/usr/bin/gencnval\t     /usr/bin/gxl2gv\n",
            "/usr/bin/gendict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TagN1KWwLPrI"
      },
      "source": [
        "# Upload the Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnLx3pVtLTca",
        "outputId": "6db1c185-a874-46fa-e991-ad1e3f4f3781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Cuda_Colab_study'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 96 (delta 44), reused 29 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (96/96), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chiyanglin-AStar/Cuda_Colab_study.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmmtqCzVMECe",
        "outputId": "4cbea017-733f-4cbe-b3a9-15f2a6002bc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda_Colab_study  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljBaItYiMHaK",
        "outputId": "2deaefbe-03c3-41d6-92b8-34f60ff24934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Cuda_Colab_study/basic_tutorial\n"
          ]
        }
      ],
      "source": [
        "%cd Cuda_Colab_study/basic_tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA tutorial part1\n",
        "ref : https://github.com/CodedK/CUDA-by-Example-source-code-for-the-book-s-examples-\n"
      ],
      "metadata": {
        "id": "7n5fWSM11D2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile book.h\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and\n",
        " * proprietary rights in and to this software and related documentation.\n",
        " * Any use, reproduction, disclosure, or distribution of this software\n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA)\n",
        " * associated with this source code for terms and conditions that govern\n",
        " * your use of this NVIDIA software.\n",
        " *\n",
        " */\n",
        "\n",
        "\n",
        "#ifndef __BOOK_H__\n",
        "#define __BOOK_H__\n",
        "#include <stdio.h>\n",
        "\n",
        "static void HandleError( cudaError_t err,\n",
        "                         const char *file,\n",
        "                         int line ) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ),\n",
        "                file, line );\n",
        "        exit( EXIT_FAILURE );\n",
        "    }\n",
        "}\n",
        "#define HANDLE_ERROR( err ) (HandleError( err, __FILE__, __LINE__ ))\n",
        "\n",
        "\n",
        "#define HANDLE_NULL( a ) {if (a == NULL) { \\\n",
        "                            printf( \"Host memory failed in %s at line %d\\n\", \\\n",
        "                                    __FILE__, __LINE__ ); \\\n",
        "                            exit( EXIT_FAILURE );}}\n",
        "\n",
        "template< typename T >\n",
        "void swap( T& a, T& b ) {\n",
        "    T t = a;\n",
        "    a = b;\n",
        "    b = t;\n",
        "}\n",
        "\n",
        "\n",
        "void* big_random_block( int size ) {\n",
        "    unsigned char *data = (unsigned char*)malloc( size );\n",
        "    HANDLE_NULL( data );\n",
        "    for (int i=0; i<size; i++)\n",
        "        data[i] = rand();\n",
        "\n",
        "    return data;\n",
        "}\n",
        "\n",
        "int* big_random_block_int( int size ) {\n",
        "    int *data = (int*)malloc( size * sizeof(int) );\n",
        "    HANDLE_NULL( data );\n",
        "    for (int i=0; i<size; i++)\n",
        "        data[i] = rand();\n",
        "\n",
        "    return data;\n",
        "}\n",
        "\n",
        "\n",
        "// a place for common kernels - starts here\n",
        "\n",
        "__device__ unsigned char value( float n1, float n2, int hue ) {\n",
        "    if (hue > 360)      hue -= 360;\n",
        "    else if (hue < 0)   hue += 360;\n",
        "\n",
        "    if (hue < 60)\n",
        "        return (unsigned char)(255 * (n1 + (n2-n1)*hue/60));\n",
        "    if (hue < 180)\n",
        "        return (unsigned char)(255 * n2);\n",
        "    if (hue < 240)\n",
        "        return (unsigned char)(255 * (n1 + (n2-n1)*(240-hue)/60));\n",
        "    return (unsigned char)(255 * n1);\n",
        "}\n",
        "\n",
        "__global__ void float_to_color( unsigned char *optr,\n",
        "                              const float *outSrc ) {\n",
        "    // map from threadIdx/BlockIdx to pixel position\n",
        "    int x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int offset = x + y * blockDim.x * gridDim.x;\n",
        "\n",
        "    float l = outSrc[offset];\n",
        "    float s = 1;\n",
        "    int h = (180 + (int)(360.0f * outSrc[offset])) % 360;\n",
        "    float m1, m2;\n",
        "\n",
        "    if (l <= 0.5f)\n",
        "        m2 = l * (1 + s);\n",
        "    else\n",
        "        m2 = l + s - l * s;\n",
        "    m1 = 2 * l - m2;\n",
        "\n",
        "    optr[offset*4 + 0] = value( m1, m2, h+120 );\n",
        "    optr[offset*4 + 1] = value( m1, m2, h );\n",
        "    optr[offset*4 + 2] = value( m1, m2, h -120 );\n",
        "    optr[offset*4 + 3] = 255;\n",
        "}\n",
        "\n",
        "__global__ void float_to_color( uchar4 *optr,\n",
        "                              const float *outSrc ) {\n",
        "    // map from threadIdx/BlockIdx to pixel position\n",
        "    int x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int offset = x + y * blockDim.x * gridDim.x;\n",
        "\n",
        "    float l = outSrc[offset];\n",
        "    float s = 1;\n",
        "    int h = (180 + (int)(360.0f * outSrc[offset])) % 360;\n",
        "    float m1, m2;\n",
        "\n",
        "    if (l <= 0.5f)\n",
        "        m2 = l * (1 + s);\n",
        "    else\n",
        "        m2 = l + s - l * s;\n",
        "    m1 = 2 * l - m2;\n",
        "\n",
        "    optr[offset].x = value( m1, m2, h+120 );\n",
        "    optr[offset].y = value( m1, m2, h );\n",
        "    optr[offset].z = value( m1, m2, h -120 );\n",
        "    optr[offset].w = 255;\n",
        "}\n",
        "\n",
        "\n",
        "#if _WIN32\n",
        "    //Windows threads.\n",
        "    #include <windows.h>\n",
        "\n",
        "    typedef HANDLE CUTThread;\n",
        "    typedef unsigned (WINAPI *CUT_THREADROUTINE)(void *);\n",
        "\n",
        "    #define CUT_THREADPROC unsigned WINAPI\n",
        "    #define  CUT_THREADEND return 0\n",
        "\n",
        "#else\n",
        "    //POSIX threads.\n",
        "    #include <pthread.h>\n",
        "\n",
        "    typedef pthread_t CUTThread;\n",
        "    typedef void *(*CUT_THREADROUTINE)(void *);\n",
        "\n",
        "    #define CUT_THREADPROC void\n",
        "    #define  CUT_THREADEND\n",
        "#endif\n",
        "\n",
        "//Create thread.\n",
        "CUTThread start_thread( CUT_THREADROUTINE, void *data );\n",
        "\n",
        "//Wait for thread to finish.\n",
        "void end_thread( CUTThread thread );\n",
        "\n",
        "//Destroy thread.\n",
        "void destroy_thread( CUTThread thread );\n",
        "\n",
        "//Wait for multiple threads.\n",
        "void wait_for_threads( const CUTThread *threads, int num );\n",
        "\n",
        "#if _WIN32\n",
        "    //Create thread\n",
        "    CUTThread start_thread(CUT_THREADROUTINE func, void *data){\n",
        "        return CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)func, data, 0, NULL);\n",
        "    }\n",
        "\n",
        "    //Wait for thread to finish\n",
        "    void end_thread(CUTThread thread){\n",
        "        WaitForSingleObject(thread, INFINITE);\n",
        "        CloseHandle(thread);\n",
        "    }\n",
        "\n",
        "    //Destroy thread\n",
        "    void destroy_thread( CUTThread thread ){\n",
        "        TerminateThread(thread, 0);\n",
        "        CloseHandle(thread);\n",
        "    }\n",
        "\n",
        "    //Wait for multiple threads\n",
        "    void wait_for_threads(const CUTThread * threads, int num){\n",
        "        WaitForMultipleObjects(num, threads, true, INFINITE);\n",
        "\n",
        "        for(int i = 0; i < num; i++)\n",
        "            CloseHandle(threads[i]);\n",
        "    }\n",
        "\n",
        "#else\n",
        "    //Create thread\n",
        "    CUTThread start_thread(CUT_THREADROUTINE func, void * data){\n",
        "        pthread_t thread;\n",
        "        pthread_create(&thread, NULL, func, data);\n",
        "        return thread;\n",
        "    }\n",
        "\n",
        "    //Wait for thread to finish\n",
        "    void end_thread(CUTThread thread){\n",
        "        pthread_join(thread, NULL);\n",
        "    }\n",
        "\n",
        "    //Destroy thread\n",
        "    void destroy_thread( CUTThread thread ){\n",
        "        pthread_cancel(thread);\n",
        "    }\n",
        "\n",
        "    //Wait for multiple threads\n",
        "    void wait_for_threads(const CUTThread * threads, int num){\n",
        "        for(int i = 0; i < num; i++)\n",
        "            end_thread( threads[i] );\n",
        "    }\n",
        "\n",
        "#endif\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#endif  // __BOOK_H__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7_EZLQi0XA-",
        "outputId": "77aaa73e-9dd9-4b44-9413-ed3559c4afe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting book.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "int main( void ) {\n",
        "    printf( \"Hello, World!\\n\" );\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOMudY4ROfjN",
        "outputId": "7f491c47-554f-4a88-c482-1ca466a3d4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc hello.cu -o hello"
      ],
      "metadata": {
        "id": "YNKhm2LVOuKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm hello"
      ],
      "metadata": {
        "id": "EgBaaNMi4F9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -o hello hello.cu"
      ],
      "metadata": {
        "id": "T_fKdM-R376z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4DiI7n7O-CY",
        "outputId": "6b77131f-0fa2-4206-ed1f-c3005a248ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "book.h\tcuda_basic_tutorial.ipynb  hello  hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guOFlMWLPlFd",
        "outputId": "53221483-b087-4c72-a329-1f388bfd861d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile simple_kernel.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "__global__ void kernel( void ) {\n",
        "}\n",
        "\n",
        "int main( void ) {\n",
        "    kernel<<<1,1>>>();\n",
        "    printf( \"Hello, World!\\n\" );\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJNK13QC1ldM",
        "outputId": "852ca8e2-93bd-4523-ca73-214525a26c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing simple_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc simple_kernel.cu"
      ],
      "metadata": {
        "id": "i3vPlOm11zFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF17cG5114w8",
        "outputId": "bb660067-c4ab-4941-a72a-ccaf055b98ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile simple_kernel_para.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "__global__ void add( int a, int b, int *c ) {\n",
        "    *c = a + b;\n",
        "}\n",
        "\n",
        "int main( void ) {\n",
        "    int c;\n",
        "    int *dev_c;\n",
        "    HANDLE_ERROR( cudaMalloc( (void**)&dev_c, sizeof(int) ) );\n",
        "\n",
        "    add<<<1,1>>>( 2, 7, dev_c );\n",
        "\n",
        "    HANDLE_ERROR( cudaMemcpy( &c, dev_c, sizeof(int),\n",
        "                              cudaMemcpyDeviceToHost ) );\n",
        "    printf( \"2 + 7 = %d\\n\", c );\n",
        "    HANDLE_ERROR( cudaFree( dev_c ) );\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqKOu33I2k4k",
        "outputId": "999935ac-397c-4146-8cd9-4ba6647f17d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing simple_kernel_para.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc simple_kernel_para.cu"
      ],
      "metadata": {
        "id": "wwfT8Xnn2aQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJDSO2Y124B7",
        "outputId": "9c511e7d-ff55-4ed8-9bdd-52a759a621a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 + 7 = 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile simple_device_call.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "__device__ int addem( int a, int b ) {\n",
        "    return a + b;\n",
        "}\n",
        "\n",
        "__global__ void add( int a, int b, int *c ) {\n",
        "    *c = addem( a, b );\n",
        "}\n",
        "\n",
        "int main( void ) {\n",
        "    int c;\n",
        "    int *dev_c;\n",
        "    HANDLE_ERROR( cudaMalloc( (void**)&dev_c, sizeof(int) ) );\n",
        "\n",
        "    add<<<1,1>>>( 2, 7, dev_c );\n",
        "\n",
        "    HANDLE_ERROR( cudaMemcpy( &c, dev_c, sizeof(int),\n",
        "                              cudaMemcpyDeviceToHost ) );\n",
        "    printf( \"2 + 7 = %d\\n\", c );\n",
        "    HANDLE_ERROR( cudaFree( dev_c ) );\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwPaaswo27Ij",
        "outputId": "a07171ec-a634-486f-bbf2-f47a5294a86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing simple_device_call.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc simple_device_call.cu"
      ],
      "metadata": {
        "id": "qG-zoJuP3QRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lvRCUbp3UPr",
        "outputId": "6626ebdf-18bb-4444-ee1c-f6e0dba4ecff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 + 7 = 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile enum_gpu.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "int main( void ) {\n",
        "    cudaDeviceProp  prop;\n",
        "\n",
        "    int count;\n",
        "    HANDLE_ERROR( cudaGetDeviceCount( &count ) );\n",
        "    for (int i=0; i< count; i++) {\n",
        "        HANDLE_ERROR( cudaGetDeviceProperties( &prop, i ) );\n",
        "        printf( \"   --- General Information for device %d ---\\n\", i );\n",
        "        printf( \"Name:  %s\\n\", prop.name );\n",
        "        printf( \"Compute capability:  %d.%d\\n\", prop.major, prop.minor );\n",
        "        printf( \"Clock rate:  %d\\n\", prop.clockRate );\n",
        "        printf( \"Device copy overlap:  \" );\n",
        "        if (prop.deviceOverlap)\n",
        "            printf( \"Enabled\\n\" );\n",
        "        else\n",
        "            printf( \"Disabled\\n\");\n",
        "        printf( \"Kernel execution timeout :  \" );\n",
        "        if (prop.kernelExecTimeoutEnabled)\n",
        "            printf( \"Enabled\\n\" );\n",
        "        else\n",
        "            printf( \"Disabled\\n\" );\n",
        "\n",
        "        printf( \"   --- Memory Information for device %d ---\\n\", i );\n",
        "        printf( \"Total global mem:  %ld\\n\", prop.totalGlobalMem );\n",
        "        printf( \"Total constant Mem:  %ld\\n\", prop.totalConstMem );\n",
        "        printf( \"Max mem pitch:  %ld\\n\", prop.memPitch );\n",
        "        printf( \"Texture Alignment:  %ld\\n\", prop.textureAlignment );\n",
        "\n",
        "        printf( \"   --- MP Information for device %d ---\\n\", i );\n",
        "        printf( \"Multiprocessor count:  %d\\n\",\n",
        "                    prop.multiProcessorCount );\n",
        "        printf( \"Shared mem per mp:  %ld\\n\", prop.sharedMemPerBlock );\n",
        "        printf( \"Registers per mp:  %d\\n\", prop.regsPerBlock );\n",
        "        printf( \"Threads in warp:  %d\\n\", prop.warpSize );\n",
        "        printf( \"Max threads per block:  %d\\n\",\n",
        "                    prop.maxThreadsPerBlock );\n",
        "        printf( \"Max thread dimensions:  (%d, %d, %d)\\n\",\n",
        "                    prop.maxThreadsDim[0], prop.maxThreadsDim[1],\n",
        "                    prop.maxThreadsDim[2] );\n",
        "        printf( \"Max grid dimensions:  (%d, %d, %d)\\n\",\n",
        "                    prop.maxGridSize[0], prop.maxGridSize[1],\n",
        "                    prop.maxGridSize[2] );\n",
        "        printf( \"\\n\" );\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNLWMAcb3bL9",
        "outputId": "07aaca14-7ab6-4231-8698-33cbc7cd9a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing enum_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc enum_gpu.cu"
      ],
      "metadata": {
        "id": "jYYo3F0c3tf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dbEu4cB3xP2",
        "outputId": "a6834331-fe88-467e-baed-8f09d3d7941a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   --- General Information for device 0 ---\n",
            "Name:  Tesla T4\n",
            "Compute capability:  7.5\n",
            "Clock rate:  1590000\n",
            "Device copy overlap:  Enabled\n",
            "Kernel execution timeout :  Disabled\n",
            "   --- Memory Information for device 0 ---\n",
            "Total global mem:  15843721216\n",
            "Total constant Mem:  65536\n",
            "Max mem pitch:  2147483647\n",
            "Texture Alignment:  512\n",
            "   --- MP Information for device 0 ---\n",
            "Multiprocessor count:  40\n",
            "Shared mem per mp:  49152\n",
            "Registers per mp:  65536\n",
            "Threads in warp:  32\n",
            "Max threads per block:  1024\n",
            "Max thread dimensions:  (1024, 1024, 64)\n",
            "Max grid dimensions:  (2147483647, 65535, 65535)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile set_gpu.cu\n",
        "/*\n",
        " * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and \n",
        " * proprietary rights in and to this software and related documentation. \n",
        " * Any use, reproduction, disclosure, or distribution of this software \n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA) \n",
        " * associated with this source code for terms and conditions that govern \n",
        " * your use of this NVIDIA software.\n",
        " * \n",
        " */\n",
        "\n",
        "\n",
        "#include \"book.h\"\n",
        "\n",
        "int main( void ) {\n",
        "    cudaDeviceProp  prop;\n",
        "    int dev;\n",
        "\n",
        "    HANDLE_ERROR( cudaGetDevice( &dev ) );\n",
        "    printf( \"ID of current CUDA device:  %d\\n\", dev );\n",
        "\n",
        "    memset( &prop, 0, sizeof( cudaDeviceProp ) );\n",
        "    prop.major = 1;\n",
        "    prop.minor = 3;\n",
        "    HANDLE_ERROR( cudaChooseDevice( &dev, &prop ) );\n",
        "    printf( \"ID of CUDA device closest to revision 1.3:  %d\\n\", dev );\n",
        "\n",
        "    HANDLE_ERROR( cudaSetDevice( dev ) );\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzUdFjIT37gL",
        "outputId": "24d84f7c-576f-4a72-c9ba-e18726c8fc05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing set_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc set_gpu.cu"
      ],
      "metadata": {
        "id": "9UDti8Qr4MCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7_Frn-s4T8z",
        "outputId": "238f3362-ad87-40cd-e42b-dd0e737484ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID of current CUDA device:  0\n",
            "ID of CUDA device closest to revision 1.3:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aJrNyoNJt4v",
        "outputId": "a12071b8-e0b2-455a-88d6-73934866caf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-wlnl4r9o\n",
            "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-wlnl4r9o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPCLbxXtGbXt",
        "outputId": "1657a31e-5640-4ef5-a1e5-e94687d9fa24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<iostream>\n",
        "void c_hello(){\n",
        "    printf(\"Hello World!\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    c_hello();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c9ab307-9cfb-4c88-f9c9-ed6f0563cfd8",
        "id": "bX2TiALNRYyf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<iostream>\n",
        "#include<stdio.h>\n",
        "using namespace std;\n",
        "__global__ void cuda_hello(){\n",
        "    \n",
        "    printf(\" hello world from GPU! \\n\");\n",
        "    //cout << \"Hello World from GPU!\\n\";\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    cuda_hello<<<1,1>>>(); \n",
        "    printf(\" hello world from main! \\n\");\n",
        "    //cout << \"hello world from main!\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwvnqvY25Ion",
        "outputId": "1c596321-12dd-4a71-d729-0ed553a2b543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " hello world from main! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB_JFFpvPQz8",
        "outputId": "08161756-3388-41e7-dc20-b66aea83019c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvprof: NVIDIA (R) Cuda command line profiler\n",
            "Copyright (c) 2012 - 2020 NVIDIA Corporation\n",
            "Release version 11.1.105 (21)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "cuda_basic_tutorial-part1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('shims')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
