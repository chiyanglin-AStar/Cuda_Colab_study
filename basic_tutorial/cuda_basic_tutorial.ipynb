{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Er195Vonzia"
      },
      "source": [
        "<a href=\"https://githubtocolab.com/chiyanglin-AStar/Cuda_Colab_study/blob/master/basic_tutorial/cuda_basic_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jo3uJgJ2DhB"
      },
      "source": [
        "# Install Nvidia & other dependencies\n",
        "\n",
        "in this version , remove colab have built-in package install steps "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZAHFNCj4St8"
      },
      "source": [
        "# Show our GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvlavcVD4K7W",
        "outputId": "1f513624-161c-4111-954d-8749a7ba36db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 25 14:41:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_cjIVVP4egG"
      },
      "source": [
        "# C Compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv_ejpDm4glG",
        "outputId": "ee643e53-1c19-42fe-d7b0-b4eb7692f22a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using built-in specs.\n",
            "COLLECT_GCC=gcc\n",
            "COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/7/lto-wrapper\n",
            "OFFLOAD_TARGET_NAMES=nvptx-none\n",
            "OFFLOAD_TARGET_DEFAULT=1\n",
            "Target: x86_64-linux-gnu\n",
            "Configured with: ../src/configure -v --with-pkgversion='Ubuntu 7.5.0-3ubuntu1~18.04' --with-bugurl=file:///usr/share/doc/gcc-7/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++ --prefix=/usr --with-gcc-major-version-only --program-suffix=-7 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-bootstrap --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\n",
            "Thread model: posix\n",
            "gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04) \n"
          ]
        }
      ],
      "source": [
        "!gcc -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3fQT5o--txn"
      },
      "source": [
        "# Install CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evxzc04GGqH3",
        "outputId": "a5b619af-1e10-4803-ef12-443b358d4a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Jun__8_16:49:14_PDT_2022\n",
            "Cuda compilation tools, release 11.7, V11.7.99\n",
            "Build cuda_11.7.r11.7/compiler.31442593_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50rnK3u2DW5I",
        "outputId": "aa90d83a-85a0-4c96-a0d6-53d82c8d20a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (185.125.190.36)] [Connected to cloud.r-p\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Waiti\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 242 kB] [2 InRelease 14.2 kB/88.7 kB 16%] [Waiting for hea\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [1 InRelease gpgv 242 kB] [2 InRelease 15.6 kB/88.7 kB 18%] [Waiting for hea\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,322 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,422 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [20.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [64.0 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,141 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,990 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,096 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,545 kB]\n",
            "Fetched 13.9 MB in 3s (5,099 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!apt-get update"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGS883nPwlwh"
      },
      "source": [
        "# nvcc show version , next three cells didn't run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiHjgIZyDaEB",
        "outputId": "ee71d290-f7b8-4aec-9cfa-7974d7995a95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cuda is already the newest version (11.7.1-1).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " nvidia-cuda-toolkit : Depends: nvidia-cuda-dev (= 9.1.85-3ubuntu1) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n"
          ]
        }
      ],
      "source": [
        "!apt-get install cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKVsaAAsG6CC",
        "outputId": "15973c5b-7c24-4dac-ca7c-6ce7957790d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda_basic_tutorial.ipynb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQoXUG9dE-OU"
      },
      "source": [
        "# Install CUDA Toolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsyMK9fxFHcO",
        "outputId": "06c928b4-0d8d-40a6-92c2-05ba7df64e3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "nvidia-cuda-toolkit is already the newest version (9.1.85-3ubuntu1).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " nvidia-cuda-toolkit : Depends: nvidia-cuda-dev (= 9.1.85-3ubuntu1) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n"
          ]
        }
      ],
      "source": [
        "!apt-get install nvidia-cuda-toolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vCkuZAaqeJA",
        "outputId": "07542811-6b2a-4753-a9e1-94f495c6e319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cmake version 3.22.6\n",
            "\n",
            "CMake suite maintained and supported by Kitware (kitware.com/cmake).\n"
          ]
        }
      ],
      "source": [
        "!cmake --version "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWgJZxS5JMOG"
      },
      "source": [
        "# Colab have install cmake , may not re-install Cmake\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*  CMake is an open-source, cross-platform family of tools \n",
        "*  designed to build, test and package software.\n",
        "*  Used to control the software compilation process.\n",
        "*  by using simple platform and compiler independent configuration files, \n",
        "*  generate native makefiles and workspaces that can be used in the compiler environment of your choice.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "gbrA1dzfKvzg",
        "outputId": "6e4b1b4b-f96e-4dd6-ddc0-76bc120f4d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.9.1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install cmake"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TagN1KWwLPrI"
      },
      "source": [
        "# Upload the Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnLx3pVtLTca",
        "outputId": "8f7199c8-b2f6-4399-d342-06ec06879fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Cuda_Colab_study'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 74 (delta 32), reused 30 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chiyanglin-AStar/Cuda_Colab_study.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmmtqCzVMECe",
        "outputId": "902912f0-75d3-483a-8b5f-7ed743d55374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda_Colab_study  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljBaItYiMHaK",
        "outputId": "1e02d5f8-f8b1-4c9f-bff1-e52f1c6becfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Cuda_Colab_study/basic_tutorial\n"
          ]
        }
      ],
      "source": [
        "%cd Cuda_Colab_study/basic_tutorial"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello.cu\n",
        "#include<stdio.h>\n",
        "__global__ void cuda_hello(){\n",
        "    printf(\"Hello World from GPU!\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    cuda_hello<<<1,1>>>(); \n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "dOMudY4ROfjN",
        "outputId": "136a2fe9-87b7-4e3c-96c3-6dfd7184be68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc hello.cu -o hello"
      ],
      "metadata": {
        "id": "YNKhm2LVOuKN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "p4DiI7n7O-CY",
        "outputId": "0d8eec51-42b0-47e6-8c2d-965259a49ebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda_basic_tutorial.ipynb  hello  hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello"
      ],
      "metadata": {
        "id": "guOFlMWLPlFd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof --version"
      ],
      "metadata": {
        "id": "HB_JFFpvPQz8",
        "outputId": "08161756-3388-41e7-dc20-b66aea83019c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvprof: NVIDIA (R) Cuda command line profiler\n",
            "Copyright (c) 2012 - 2020 NVIDIA Corporation\n",
            "Release version 11.1.105 (21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aJrNyoNJt4v",
        "outputId": "57af2d26-1db9-467f-cfc3-c8896b176462"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-jr6dconk\n",
            "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-jr6dconk\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4306 sha256=060bfbba8b9626dcb2ff9103d3d556ba722fd343cbfcd2ca5c844c1663fdd521\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y7xwhf0e/wheels/ca/33/8d/3c86eb85e97d2b6169d95c6e8f2c297fdec60db6e84cb56f5e\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPCLbxXtGbXt",
        "outputId": "ad66f60f-6540-40f0-9eba-f92a7eaeaf09"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/Cuda_Colab_study/basic_tutorial/src\n",
            "Out bin /content/Cuda_Colab_study/basic_tutorial/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ref from : https://www.geeksforgeeks.org/how-to-run-cuda-c-c-on-jupyter-notebook-in-google-colaboratory/"
      ],
      "metadata": {
        "id": "AaxWQ_JgJ_Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "int main(){\n",
        "    std::cout << \"Welcome To GeeksforGeeks\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ghAgIdRF4wY",
        "outputId": "41ea5f3b-56c7-4ba0-90c7-cce0cebe86eb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome To GeeksforGeeks\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "*c = *a + *b;\n",
        "}\n",
        "int main() {\n",
        "int a, b, c;\n",
        "// host copies of variables a, b & c\n",
        "int *d_a, *d_b, *d_c;\n",
        "// device copies of variables a, b & c\n",
        "int size = sizeof(int);\n",
        "// Allocate space for device copies of a, b, c\n",
        "cudaMalloc((void **)&d_a, size);\n",
        "cudaMalloc((void **)&d_b, size);\n",
        "cudaMalloc((void **)&d_c, size);\n",
        "// Setup input values  \n",
        "c = 0;\n",
        "a = 3;\n",
        "b = 5;\n",
        "// Copy inputs to device\n",
        "cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "// Launch add() kernel on GPU\n",
        "add<<<1,1>>>(d_a, d_b, d_c);\n",
        "// Copy result back to host\n",
        "cudaError err = cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "  if(err!=cudaSuccess) {\n",
        "      printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "printf(\"result is %d\\n\",c);\n",
        "// Cleanup\n",
        "cudaFree(d_a);\n",
        "cudaFree(d_b);\n",
        "cudaFree(d_c);\n",
        "return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhcMmCXhLjLv",
        "outputId": "3730f737-5461-4b82-c715-4c3570efee5b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA error copying to Host: the provided PTX was compiled with an unsupported toolchain.\n",
            "result is 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cstdio>\n",
        "#include <iostream> \n",
        "using namespace std; \n",
        "__global__ void maxi(int* a, int* b, int n){\n",
        "    int block = 256 * blockIdx.x;\n",
        "    int max = 0; \n",
        "    for (int i = block; i < min(256 + block, n); i++) { \n",
        "        if (max < a[i]) {\n",
        "            max = a[i];\n",
        "        }\n",
        "    }\n",
        "    b[blockIdx.x] = max;\n",
        "} \n",
        "int main(){ \n",
        "    int n;\n",
        "    n = 3 >> 2;\n",
        "    int a[n]; \n",
        "    for (int i = 0; i < n; i++) {\n",
        "        a[i] = rand() % n;\n",
        "        cout << a[i] << \"\\t\";\n",
        "    }\n",
        " \n",
        "    cudaEvent_t start, end;\n",
        "    int *ad, *bd;\n",
        "    int size = n * sizeof(int);\n",
        "    cudaMalloc(&ad, size);\n",
        "    cudaMemcpy(ad, a, size, cudaMemcpyHostToDevice);\n",
        "    int grids = ceil(n * 1.0f / 256.0f);\n",
        "    cudaMalloc(&bd, grids * sizeof(int));\n",
        " \n",
        "    dim3 grid(grids, 1);\n",
        "    dim3 block(1, 1);\n",
        " \n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventRecord(start); \n",
        "    while (n > 1) {\n",
        "        maxi<<<grids, block>>>(ad, bd, n);\n",
        "        n = ceil(n * 1.0f / 256.0f);\n",
        "        cudaMemcpy(ad, bd, n * sizeof(int), cudaMemcpyDeviceToDevice);\n",
        "    } \n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        " \n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, start, end);\n",
        " \n",
        "    int ans[2];\n",
        "    cudaMemcpy(ans, ad, 4, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    cout << \"The maximum element is : \" << ans[0] << endl;\n",
        " \n",
        "    cout << \"The time required : \";\n",
        "    cout << time << endl;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4gO3fzgKQSd",
        "outputId": "47b5e3d7-5a24-45c8-ac81-15dbe30b505c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#define N  64\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "  if (err != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "  }\n",
        "  return err;\n",
        "}\n",
        "__global__ void matrixMulGPU( int * a, int * b, int * c )\n",
        "{\n",
        "  /*\n",
        "   * Build out this kernel.\n",
        "   */\n",
        "    int row = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int col = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    \n",
        "    int val = 0;\n",
        "    if (row < N && col < N) {\n",
        "      for (int i = 0; i < N; ++i) {\n",
        "         val += a[row * N + i] * b[i * N + col];\n",
        "       }\n",
        "    \n",
        "      c[row * N + col] = val;\n",
        "    }\n",
        "}\n",
        " /*\n",
        " * This CPU function already works, and will run to create a solution matrix\n",
        " * against which to verify your work building out the matrixMulGPU kernel.\n",
        " */\n",
        "void matrixMulCPU( int * a, int * b, int * c )\n",
        "{\n",
        "  int val = 0;for( int row = 0; row < N; ++row )\n",
        "    for( int col = 0; col < N; ++col )\n",
        "    {\n",
        "      val = 0;\n",
        "      for ( int k = 0; k < N; ++k )\n",
        "        val += a[row * N + k] * b[k * N + col];\n",
        "      c[row * N + col] = val;\n",
        "    }\n",
        "}int main()\n",
        "{\n",
        "  int *a, *b, *c_cpu, *c_gpu; // Allocate a solution matrix for both the CPU and the GPU operationsint \n",
        "  int size = N * N * sizeof (int); // Number of bytes of an N x N matrix// Allocate memory\n",
        "  cudaMallocManaged (&a, size);\n",
        "  cudaMallocManaged (&b, size);\n",
        "  cudaMallocManaged (&c_cpu, size);\n",
        "  cudaMallocManaged (&c_gpu, size);// Initialize memory; create 2D matrices\n",
        "  for( int row = 0; row < N; ++row )\n",
        "    for( int col = 0; col < N; ++col )\n",
        "    {\n",
        "      a[row*N + col] = row;\n",
        "      b[row*N + col] = col+2;\n",
        "      c_cpu[row*N + col] = 0;\n",
        "      c_gpu[row*N + col] = 0;\n",
        "    }\n",
        "   /*\n",
        "   * Assign `threads_per_block` and `number_of_blocks` 2D values\n",
        "   * that can be used in matrixMulGPU above.\n",
        "   */\n",
        "  dim3 threads_per_block(32, 32, 1);\n",
        "  dim3 number_of_blocks(N / threads_per_block.x + 1, N / threads_per_block.y + 1, 1);\n",
        "  matrixMulGPU <<< number_of_blocks, threads_per_block >>> ( a, b, c_gpu );checkCudaErr(cudaDeviceSynchronize(), \"Syncronization\");\n",
        "  checkCudaErr(cudaGetLastError(), \"GPU\");// Call the CPU version to check our work\n",
        "  matrixMulCPU( a, b, c_cpu );// Compare the two answers to make sure they are equal\n",
        "  bool error = false;\n",
        "  for( int row = 0; row < N && !error; ++row )\n",
        "    for( int col = 0; col < N && !error; ++col )\n",
        "      if (c_cpu[row * N + col] != c_gpu[row * N + col])\n",
        "      {\n",
        "        printf(\"FOUND ERROR at c[%d][%d]\\n\", row, col);\n",
        "        error = true;\n",
        "        break;\n",
        "      }\n",
        "  if (!error)\n",
        "    printf(\"Success!\\n\");// Free all our allocated memory\n",
        "  cudaFree(a);\n",
        "  cudaFree(b);\n",
        "  cudaFree( c_cpu );\n",
        "  cudaFree( c_gpu );\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JfRtLevMAb3",
        "outputId": "9bf7c62f-1579-4501-f4e7-33f3f40ebfc9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile geek_cuda_ex2.cu\n",
        "#include <cstdio>\n",
        "#include <iostream> \n",
        "using namespace std; \n",
        "__global__ void maxi(int* a, int* b, int n){\n",
        "    int block = 256 * blockIdx.x;\n",
        "    int max = 0; \n",
        "    for (int i = block; i < min(256 + block, n); i++) { \n",
        "        if (max < a[i]) {\n",
        "            max = a[i];\n",
        "        }\n",
        "    }\n",
        "    b[blockIdx.x] = max;\n",
        "} \n",
        "int main(){ \n",
        "    int n;\n",
        "    n = 3 >> 2;\n",
        "    int a[n]; \n",
        "    for (int i = 0; i < n; i++) {\n",
        "        a[i] = rand() % n;\n",
        "        cout << a[i] << \"\\t\";\n",
        "    }\n",
        " \n",
        "    cudaEvent_t start, end;\n",
        "    int *ad, *bd;\n",
        "    int size = n * sizeof(int);\n",
        "    cudaMalloc(&ad, size);\n",
        "    cudaMemcpy(ad, a, size, cudaMemcpyHostToDevice);\n",
        "    int grids = ceil(n * 1.0f / 256.0f);\n",
        "    cudaMalloc(&bd, grids * sizeof(int));\n",
        " \n",
        "    dim3 grid(grids, 1);\n",
        "    dim3 block(1, 1);\n",
        " \n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventRecord(start); \n",
        "    while (n > 1) {\n",
        "        maxi<<<grids, block>>>(ad, bd, n);\n",
        "        n = ceil(n * 1.0f / 256.0f);\n",
        "        cudaMemcpy(ad, bd, n * sizeof(int), cudaMemcpyDeviceToDevice);\n",
        "    } \n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        " \n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, start, end);\n",
        " \n",
        "    int ans[2];\n",
        "    cudaMemcpy(ans, ad, 4, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    cout << \"The maximum element is : \" << ans[0] << endl;\n",
        " \n",
        "    cout << \"The time required : \";\n",
        "    cout << time << endl;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBuRKxG5LEPN",
        "outputId": "07e42a00-a3e9-4e93-8861-a7861747e43c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting geek_cuda_ex2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe-9B2sYLUMl",
        "outputId": "c9f84791-c6e4-45f1-b913-9604e226cd1f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda_basic_tutorial.ipynb  geek_cuda_ex2.cu  src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc geek_cuda_ex2.cu -o geek_cu2"
      ],
      "metadata": {
        "id": "ZtUjGFYyM-7d"
      },
      "execution_count": 43,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "CUDA-GPU-simple.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('shims')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}